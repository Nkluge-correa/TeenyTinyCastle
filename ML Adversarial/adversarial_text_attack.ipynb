{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Adversarial _text_ with `TextAttack`\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n",
    "\n",
    "**_Adversarial machine learning_ is the study of the attacks on [machine learning](https://en.wikipedia.org/wiki/Machine_learning \"Machine learning\") algorithms and the defenses against such attacks. Recent surveys expose the fact that practitioners report a dire need for better protecting machine learning systems in real-world applications.**\n",
    "\n",
    "**In this notebook, we will be exploring one of the functionalities of the `textattack` library.**\n",
    "\n",
    "> TextAttack is a Python framework for adversarial attacks, data augmentation, and model training in NLP.\n",
    "\n",
    "**We already work with the `text augmentation` on our [notebook](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/bbe9c0a77499fa68de7c6d53bf5ef7e0b43a25e0/ML%20Adversarial/model_extraction_nlp.ipynb) about `model extraction attacks`. But in this notebook, we will develop and attack a language model trained on sentiment classification.**\n",
    "\n",
    "![textattack](https://miro.medium.com/proxy/1*_JW1JaMpK_fVGld8pd1_JQ.gif)\n",
    "\n",
    "**In this notebook, similar to [this](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/64d0693c28786ce42149411bec8b3b42520fc4df/ML%20Explainability/NLP%20Interpreter%20(en)/model_maker_en.ipynb) and [this](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/64d0693c28786ce42149411bec8b3b42520fc4df/ML%20Explainability/NLP%20Interpreter%20(pt)/model_maker_pt.ipynb) other tutorials from the Teeny-Tiny Castle üè∞, we will create a `Bidirectional long-short term memory(bi-lstm)` for sentiment classification.**\n",
    "\n",
    "**We will be using a dataset that was put together by combining several datasets for sentiment classification available on [Kaggle](https://www.kaggle.com/):**\n",
    "\n",
    "- The `IMDB 50K` [dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?select=IMDB+Dataset.csv): _0K movie reviews for natural language processing or Text analytics._\n",
    "- The `Twitter US Airline Sentiment` [dataset](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment):_originated from the  [Crowdflower's Data for Everyone library](http://www.crowdflower.com/data-for-everyone)._\n",
    "- Our `google_play_apps_review` _dataset: built using the `google_play_scraper` in [this notebook](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/64d0693c28786ce42149411bec8b3b42520fc4df/ML%20Explainability/NLP%20Interpreter%20(en)/scrape(en).ipynb)._\n",
    "- The `EcoPreprocessed` [dataset](https://www.kaggle.com/datasets/pradeeshprabhakar/preprocessed-dataset-sentiment-analysis): _scrapped amazon product reviews_\n",
    "\n",
    "**The final result is the `sentiment_analysis_dataset.csv` available for download [here](https://drive.google.com/uc?export=download&id=1_ijhnVLHddM7Cm3R3vfqBB-svw6iNfpv).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85084</th>\n",
       "      <td>3543</td>\n",
       "      <td>yaaa cool use last weeks give good response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85085</th>\n",
       "      <td>3544</td>\n",
       "      <td>years daughter love alexa enjoy alexa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85086</th>\n",
       "      <td>3545</td>\n",
       "      <td>yes popular but doesnt use except listen songs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85087</th>\n",
       "      <td>3546</td>\n",
       "      <td>yo alexa love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85088</th>\n",
       "      <td>3547</td>\n",
       "      <td>yo yo yo love go if want one smart speaker val...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85089 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             review  \\\n",
       "0               0  One of the other reviewers has mentioned that ...   \n",
       "1               1  A wonderful little production. <br /><br />The...   \n",
       "2               2  I thought this was a wonderful way to spend ti...   \n",
       "3               3  Basically there's a family where a little boy ...   \n",
       "4               4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "...           ...                                                ...   \n",
       "85084        3543        yaaa cool use last weeks give good response   \n",
       "85085        3544              years daughter love alexa enjoy alexa   \n",
       "85086        3545  yes popular but doesnt use except listen songs...   \n",
       "85087        3546                                      yo alexa love   \n",
       "85088        3547  yo yo yo love go if want one smart speaker val...   \n",
       "\n",
       "       sentiment  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              1  \n",
       "...          ...  \n",
       "85084          1  \n",
       "85085          1  \n",
       "85086          1  \n",
       "85087          1  \n",
       "85088          1  \n",
       "\n",
       "[85089 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    'https://drive.google.com/uc?export=download&id=1_ijhnVLHddM7Cm3R3vfqBB-svw6iNfpv', \n",
    "    'sentiment_analysis_dataset.csv'\n",
    ")\n",
    "\n",
    "df = pd.read_csv('sentiment_analysis_dataset.csv')\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following cells will train a `Bidirectional long-short term memory (bi-lstm)` for binary sentiment classification (Negative versus Positive). The training process may take a while, so if you want to skip this, you can load our `pre-trained senti-model` directly below the next cell. This is the same model we trained in [this](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/bbe9c0a77499fa68de7c6d53bf5ef7e0b43a25e0/ML%20Explainability/NLP%20Interpreter%20(en)/model_maker_en.ipynb) notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.10.0\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 50)          150000    \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, None, 128)        58880     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307,825\n",
      "Trainable params: 307,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2128/2128 [==============================] - 94s 42ms/step - loss: 0.4672 - accuracy: 0.7734\n",
      "Epoch 2/20\n",
      "2128/2128 [==============================] - 97s 46ms/step - loss: 0.3702 - accuracy: 0.8408\n",
      "Epoch 3/20\n",
      "2128/2128 [==============================] - 98s 46ms/step - loss: 0.3171 - accuracy: 0.8679\n",
      "Epoch 4/20\n",
      "2128/2128 [==============================] - 92s 43ms/step - loss: 0.2809 - accuracy: 0.8852\n",
      "Epoch 5/20\n",
      "2128/2128 [==============================] - 93s 44ms/step - loss: 0.2560 - accuracy: 0.8960\n",
      "Epoch 6/20\n",
      "2128/2128 [==============================] - 97s 46ms/step - loss: 0.2355 - accuracy: 0.9045\n",
      "Epoch 7/20\n",
      "2128/2128 [==============================] - 98s 46ms/step - loss: 0.2110 - accuracy: 0.9165\n",
      "Epoch 8/20\n",
      "2128/2128 [==============================] - 101s 47ms/step - loss: 0.1892 - accuracy: 0.9265\n",
      "Epoch 9/20\n",
      "2128/2128 [==============================] - 101s 47ms/step - loss: 0.1670 - accuracy: 0.9364\n",
      "Epoch 10/20\n",
      "2128/2128 [==============================] - 114s 53ms/step - loss: 0.1486 - accuracy: 0.9451\n",
      "Epoch 11/20\n",
      "2128/2128 [==============================] - 104s 49ms/step - loss: 0.1286 - accuracy: 0.9538\n",
      "Epoch 12/20\n",
      "2128/2128 [==============================] - 105s 49ms/step - loss: 0.1106 - accuracy: 0.9611\n",
      "Epoch 13/20\n",
      "2128/2128 [==============================] - 112s 53ms/step - loss: 0.0959 - accuracy: 0.9663\n",
      "Epoch 14/20\n",
      "2128/2128 [==============================] - 100s 47ms/step - loss: 0.0824 - accuracy: 0.9715\n",
      "Epoch 15/20\n",
      "2128/2128 [==============================] - 102s 48ms/step - loss: 0.0696 - accuracy: 0.9766\n",
      "Epoch 16/20\n",
      "2128/2128 [==============================] - 101s 47ms/step - loss: 0.0628 - accuracy: 0.9797\n",
      "Epoch 17/20\n",
      "2128/2128 [==============================] - 101s 48ms/step - loss: 0.0539 - accuracy: 0.9820\n",
      "Epoch 18/20\n",
      "2128/2128 [==============================] - 102s 48ms/step - loss: 0.0455 - accuracy: 0.9851\n",
      "Epoch 19/20\n",
      "2128/2128 [==============================] - 104s 49ms/step - loss: 0.0436 - accuracy: 0.9853\n",
      "Epoch 20/20\n",
      "2128/2128 [==============================] - 111s 52ms/step - loss: 0.0377 - accuracy: 0.9877\n",
      "532/532 [==============================] - 15s 26ms/step - loss: 0.6223 - accuracy: 0.8673\n",
      "Final Loss: 0.62.\n",
      "Final Performance: 86.73 %.\n"
     ]
    }
   ],
   "source": [
    "x = list(df.review)\n",
    "y = list(df.sentiment)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = np.array(y_train).astype(float)\n",
    "y_test = np.array(y_test).astype(float)\n",
    "\n",
    "\n",
    "vocab_size = 3000\n",
    "embed_size = 50\n",
    "max_len = 256\n",
    "tokenizer = Tokenizer(num_words=vocab_size,\n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      lower=True,\n",
    "                      split=\" \",\n",
    "                      oov_token=\"<OOV>\")\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "training_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "training_padded = pad_sequences(\n",
    "    training_sequences, maxlen=max_len, truncating='post')\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size,\n",
    "                              input_length=max_len)(inputs)\n",
    "\n",
    "x = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss=tf.losses.BinaryCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "model.fit(training_padded,\n",
    "          y_train,\n",
    "          epochs=20,\n",
    "          verbose=1)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=256, truncating='post')\n",
    "\n",
    "test_loss_score, test_acc_score = model.evaluate(test_padded, y_test)\n",
    "\n",
    "print(f'Final Loss: {round(test_loss_score, 2)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')\n",
    "\n",
    "# If you would like to save your model/tokenizer, uncomment the lines below\n",
    "\n",
    "#model.save(\"models\\senti_model.h5\")\n",
    "\n",
    "#import io\n",
    "#import json\n",
    "#from keras.preprocessing.text import tokenizer_from_json\n",
    "\n",
    "#tokenizer_json = tokenizer.to_json()\n",
    "#with io.open('tokenizer_senti_model.json', 'w', encoding='utf-8') as f:\n",
    "#    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is hard to say something about a model so simple\n",
      "\n",
      "Negative Sentiment üòî 100% | Positive Sentiment üòä 0%\n",
      "**************************************************\n",
      "you call this NLP, please, my nana can do it better in pascal\n",
      "\n",
      "Negative Sentiment üòî 85% | Positive Sentiment üòä 15%\n",
      "**************************************************\n",
      "this model is garbage, i wont my money back\n",
      "\n",
      "Negative Sentiment üòî 100% | Positive Sentiment üòä 0%\n",
      "**************************************************\n",
      "is nice to see philosophers doing machine learning\n",
      "\n",
      "Negative Sentiment üòî 0% | Positive Sentiment üòä 100%\n",
      "**************************************************\n",
      "this is a great and wonderful example of NLP\n",
      "\n",
      "Negative Sentiment üòî 0% | Positive Sentiment üòä 100%\n",
      "**************************************************\n",
      "this model is great, one of the best models ever done by a human\n",
      "\n",
      "Negative Sentiment üòî 0% | Positive Sentiment üòä 100%\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer, tokenizer_from_json\n",
    "\n",
    "model = keras.models.load_model('models\\senti_model.h5')\n",
    "\n",
    "with open('models\\\\tokenizer_senti_model.json') as f:\n",
    "    data = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(data)\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "strings = [\n",
    "    'is hard to say something about a model so simple',\n",
    "    'you call this NLP, please, my nana can do it better in pascal',\n",
    "    'this model is garbage, i wont my money back',\n",
    "    'is nice to see philosophers doing machine learning',\n",
    "    'this is a great and wonderful example of NLP',\n",
    "    'this model is great, one of the best models ever done by a human'\n",
    "]\n",
    "\n",
    "preds = model.predict(\n",
    "        keras.preprocessing.sequence.pad_sequences(\n",
    "                                                    tokenizer.texts_to_sequences(strings),\n",
    "                                                    maxlen=256,\n",
    "                                                    truncating='post'\n",
    "                                                ),\n",
    "    verbose=0)\n",
    "\n",
    "for i, string in enumerate(strings):\n",
    "    print(f'{string}\\n')\n",
    "    print(f'Negative Sentiment üòî {round((1 - preds[i][0]) * 100)}% | Positive Sentiment üòä {round(preds[i][0] * 100)}%\\n{\"*\" * 50}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model seems to be working fine! Now, let us change this**üôÉ\n",
    "\n",
    "**Using the `textattack`, we can _wrap_ a model (like a Keras, TensorFlow, Scikitlearn, or AllenNLP model) using the `ModelWrapper` class. Then, using the `call` method, we can create a function that gives us the prediction scores for our model output.**\n",
    "\n",
    "**Creating this function/method will be a specific-task, given the natural output format of your model. Below, you can find out how to turn the output of a `sigmoid function` (the last layer of our `bi-lstm`) into a torch tensor that contains the probabilities for each of the sentiment classes ($0$ for negative, $1$ for positive).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class ModelWrapper(ModelWrapper):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, text_input_list):\n",
    "        text_array = tokenizer.texts_to_sequences(text_input_list)\n",
    "        padded_text_array = keras.preprocessing.sequence.pad_sequences(\n",
    "                                                    text_array,\n",
    "                                                    maxlen=256,\n",
    "                                                    truncating='post'\n",
    "                                                )\n",
    "        preds = self.model.predict(padded_text_array, verbose=0)\n",
    "        logits = torch.tensor(preds)\n",
    "        logits = logits.squeeze(dim=-1)\n",
    "        final_preds = torch.stack((1-logits, logits), dim=1)\n",
    "        return final_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let us see the outputs of our `ModelWrapper`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9923e-01, 7.7294e-04],\n",
       "        [8.4638e-01, 1.5362e-01],\n",
       "        [9.9993e-01, 7.4672e-05],\n",
       "        [5.7155e-04, 9.9943e-01],\n",
       "        [1.0251e-03, 9.9897e-01],\n",
       "        [1.2398e-05, 9.9999e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelWrapper(model)([\n",
    "    'is hard to say something about a model so simple',\n",
    "    'you call this NLP, please, my nana can do it better in pascal',\n",
    "    'this model is garbage, i wont my money back',\n",
    "    'is nice to see philosophers doing machine learning',\n",
    "    'this is a great and wonderful example of NLP',\n",
    "    'this model is great, one of the best models ever done by a human'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exactly what we wanted, and the probabilities are in agreement with the input. Now we can just call an attack recipe from the `Attack Recipes` in`textattack`.**\n",
    "\n",
    "**However, we need something to attack. `Textattack` allows you to use `HuggingFace` Datasets for the attack. You can also use your own dataset for this.**\n",
    "\n",
    "**The `textattack.datasets.Dataset` method takes as input a list of tuples, e.g., `[('some text', label_1), ('some other text', label_2)]`. Below we transform the examples used above into a mini-dataset. `Textattack` will use these samples to create adversarial examples against our model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [\n",
    "    ('is hard to say something about a model so simple', 0),\n",
    "    ('you call this NLP, please, my nana can do it better in pascal', 0),\n",
    "    ('this model is garbage, i wont my money back', 0),\n",
    "    ('is nice to see philosophers doing machine learning', 1),\n",
    "    ('this is a great and wonderful example of NLP', 1),\n",
    "    ('this model is great, one of the best models ever done by a human', 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You could also transform a portion of your dataset into a list of tuples (`text, label`). You can transform any list of labeled text samples into a `textattack.datasets`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textattack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data\\sentiment_analysis_dataset.csv')\n",
    "\n",
    "_, x_test, _, y_test = train_test_split(\n",
    "   list(df.review), list(df.sentiment), test_size=0.2, random_state=42)\n",
    "\n",
    "y_test = np.array(y_test).astype(float)\n",
    "\n",
    "data=[(x_test[i], int(y_test[i])) for i in range(len(x_test))]\n",
    "np.random.shuffle(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have a dataset. We can call one of the attack recipes from `textattack`. All available recipes correspond to attacks from the literature in Adversarial ML.**\n",
    "\n",
    "**Attack recipes allow you to create an `Attack` object where the goal function (determines both the conditions under which the attack is successful), transformation (the adversarial perturbations produced in the samples of the dataset), constraints (the limitations imposed on theses transformations), and search method are those specified in the origin paper.**\n",
    "\n",
    "**Here you can find a list of _fast_ attack recipes form `textattack`:**\n",
    "\n",
    "- `PWWSRen2019`: in this attack, words are perturbed by a synonym-swap transformation based on a combination of their saliency score (e.g., _the importance of a linguistic feature_) and maximum word-swap effectiveness (proposed in \"[Generating Natural Langauge Adversarial Examples through Probability Weighted Word Saliency](https://aclanthology.org/P19-1103/)\");\n",
    "- `CheckList2020`: this attack focuses on several √ßangiage perturbations, like contractions, extensions, changing names, numbers, and locations (proposed in \"[Beyond Accuracy: Behavioral Testing of NLP models with CheckList](https://aclanthology.org/2020.acl-main.442/)\");\n",
    "- `DeepWordBugGao2018`: this attack performs simple character-level transformations (_changes certain letters of a word_) to the highest-ranked tokens (proposed in [Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers](https://arxiv.org/abs/1801.04354));\n",
    "- `IGAWang2019`: this attack can be characterized as a synonym substitution-based attack that preserves the syntactic structure and semantic information of the original text (proposed in [Natural Language Adversarial Attacks and Defenses in Word Level](http://arxiv.org/abs/1909.06723));\n",
    "- `InputReductionFeng2018`: this attack does not cause the model to misclassify a sample. However, it removes words with low saliency scores, creating nonsensical sentences that the model classifies with high confidence as the original predicted class (proposed in [Pathologies of Neural Models Make Interpretations Difficult](https://arxiv.org/abs/1804.07781));\n",
    "- `Pruthi2019`: this attack focuses on a small number of character-level changes that simulate common typos, like _swapping neighboring characters, deleting characters, inserting characters,_ and _swapping characters for adjacent keys_ on a **QWERTY** keyboard (proposed in [Pruthi2019: Combating with Robust Word Recognition](https://arxiv.org/abs/1905.11268));\n",
    "- `TextBuggerLi2018`: this is a general attack framework for generating adversarial texts (proposed in [TextBugger: Generating Adversarial Text Against Real-world Applications](https://arxiv.org/abs/1812.05271)).\n",
    "\n",
    "**In the example below, we will use the `IGAWang2019` recipe.**\n",
    "\n",
    "**The `Attacker` class also accepts additional arguments (full list [here](https://textattack.readthedocs.io/en/latest/api/attacker.html#attackargs)). Below we are passing a `log_to_txt ` argument equal to the name of `.txt` file (all attacks will be saved in this file).**\n",
    "\n",
    "**For clarity purposes, all perturbed words are highlighted with [[ ]].**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.functional.Functional'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to text file at path textattack_logs_IGAWang2019.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): ImprovedGeneticAlgorithm(\n",
      "    (pop_size):  60\n",
      "    (max_iters):  20\n",
      "    (temp):  0.3\n",
      "    (give_up_if_no_improvement):  False\n",
      "    (post_crossover_check):  False\n",
      "    (max_crossover_retries):  20\n",
      "    (max_replace_times_per_index):  5\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): MaxWordsPerturbed(\n",
      "        (max_percent):  0.2\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (max_mse_dist):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  17%|‚ñà‚ñã        | 1/6 [00:00<00:03,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[0 (100%)]] --> [[1 (83%)]]\n",
      "\n",
      "is hard to say something about a model so [[simple]]\n",
      "\n",
      "is hard to say something about a model so [[easy]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:01<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[0 (85%)]] --> [[1 (92%)]]\n",
      "\n",
      "you [[call]] this NLP, please, my nana can do it better in pascal\n",
      "\n",
      "you [[calls]] this NLP, please, my nana can do it better in pascal\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:09<00:09,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[0 (100%)]] --> [[1 (100%)]]\n",
      "\n",
      "this [[model]] is [[garbage]], i [[wont]] my [[money]] back\n",
      "\n",
      "this [[mannequins]] is [[detritus]], i [[habit]] my [[cash]] back\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:11<00:05,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[1 (100%)]] --> [[0 (66%)]]\n",
      "\n",
      "is [[nice]] to see philosophers doing [[machine]] learning\n",
      "\n",
      "is [[agreeable]] to see philosophers doing [[computer]] learning\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:17<00:03,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[1 (100%)]] --> [[0 (57%)]]\n",
      "\n",
      "this is a [[great]] and [[wonderful]] example of NLP\n",
      "\n",
      "this is a [[massive]] and [[admirable]] example of NLP\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 0 / 0 / 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:34<00:00,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[1 (100%)]] --> [[0 (54%)]]\n",
      "\n",
      "this model is [[great]], one of the best models ever [[done]] by a [[human]]\n",
      "\n",
      "this model is [[unbelievable]], one of the best models ever [[finished]] by a [[humans]]\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 6      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 21.8%  |\n",
      "| Average num. words per input: | 10.5   |\n",
      "| Avg num queries:              | 464.0  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x18726f52430>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x18727b68970>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x187272b9af0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x18725d8a7c0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x1872980efd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x18725168cd0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper = ModelWrapper(model)\n",
    "\n",
    "import textattack\n",
    "from textattack.attack_recipes import IGAWang2019\n",
    "from textattack import Attacker\n",
    "\n",
    "data = [\n",
    "    ('is hard to say something about a model so simple', 0),\n",
    "    ('you call this NLP, please, my nana can do it better in pascal', 0),\n",
    "    ('this model is garbage, i wont my money back', 0),\n",
    "    ('is nice to see philosophers doing machine learning', 1),\n",
    "    ('this is a great and wonderful example of NLP', 1),\n",
    "    ('this model is great, one of the best models ever done by a human', 1)\n",
    "]\n",
    "\n",
    "dataset = textattack.datasets.Dataset(data)\n",
    "attack = IGAWang2019.build(model_wrapper)\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=6,\n",
    "    log_to_txt =\"textattack_logs_IGAWang2019.txt\"\n",
    ")\n",
    "attacker = Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let us try another recipe!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.functional.Functional'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to text file at path textattack_logs_DeepWordBugGao2018.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterSubstitution(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): LevenshteinEditDistance(\n",
      "        (max_edit_distance):  30\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  17%|‚ñà‚ñã        | 1/6 [00:00<00:01,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[0 (100%)]] --> [[1 (91%)]]\n",
      "\n",
      "is hard to say something about a [[model]] so simple\n",
      "\n",
      "is hard to say something about a [[mode]] so simple\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:00<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[0 (85%)]] --> [[1 (97%)]]\n",
      "\n",
      "you [[call]] this NLP, please, my nana can do it better in pascal\n",
      "\n",
      "you [[all]] this NLP, please, my nana can do it better in pascal\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:01<00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[0 (100%)]] --> [[1 (66%)]]\n",
      "\n",
      "this [[model]] is [[garbage]], i wont my [[money]] [[back]]\n",
      "\n",
      "this [[gmodel]] is [[arbage]], i wont my [[Voney]] [[Hack]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:01<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[1 (100%)]] --> [[0 (61%)]]\n",
      "\n",
      "is [[nice]] to [[see]] philosophers doing [[machine]] learning\n",
      "\n",
      "is [[Wice]] to [[sde]] philosophers doing [[Nachine]] learning\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 1 / 0 / 5:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:01<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[1 (100%)]] --> [[[FAILED]]]\n",
      "\n",
      "this is a great and wonderful example of NLP\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 1 / 0 / 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[1 (100%)]] --> [[0 (67%)]]\n",
      "\n",
      "this model is [[great]], [[one]] of the [[best]] models [[ever]] [[done]] by a [[human]]\n",
      "\n",
      "this model is [[gCreat]], [[noe]] of the [[Eest]] models [[evBer]] [[dTne]] by a [[hVuman]]\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 5      |\n",
      "| Number of failed attacks:     | 1      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 16.67% |\n",
      "| Attack success rate:          | 83.33% |\n",
      "| Average perturbed word %:     | 28.5%  |\n",
      "| Average num. words per input: | 10.5   |\n",
      "| Avg num queries:              | 19.0   |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x1871aa115b0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x1872727a640>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x1871af03850>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x18728acffd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x1872514c970>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x18727e00520>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textattack.attack_recipes import DeepWordBugGao2018\n",
    "\n",
    "attack = DeepWordBugGao2018.build(model_wrapper)\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=6,\n",
    "    log_to_txt =\"textattack_logs_DeepWordBugGao2018.txt\"\n",
    ")\n",
    "attacker = Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language models are the foundation behind various applications such as Q&A, chatbots, machine translation, and text classification. However, the security vulnerabilities associated with ML-trained language models are still largely unknown, which is highly concerning.**\n",
    "\n",
    "**To remedy this, developers must use the same tools that attackers use to fool models. For example, creating adversarial examples with libraries like `textattack` (_which also provide data augmentation_) can supply adversarial databases to tune and improve language models, making them more robust.**\n",
    "\n",
    "**At the same time, other strategies are possible. As demonstrated by [Xiaosen Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+X), [Hao Jin](https://arxiv.org/search/cs?searchtype=author&query=Jin%2C+H), [Yichen Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+Y), and [Kun He](https://arxiv.org/search/cs?searchtype=author&query=He%2C+K), since most of the attacks used in the literature are synonym-based attacks, [Synonym Encoding Methods](https://arxiv.org/abs/1812.05271) can help models to cluster synonyms to a unique encoding, thus eliminating possible adversarial perturbations.**\n",
    "\n",
    "---\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
