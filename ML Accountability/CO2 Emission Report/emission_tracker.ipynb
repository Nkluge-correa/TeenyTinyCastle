{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Carbon Footprint of ML Models with CodeCarbon\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n",
    "\n",
    "![image](https://co2living.com/wp-content/uploads/2019/02/Reduce-Your-Carbon-Footprint.jpg)\n",
    "\n",
    "A **carbon footprint** is the total [greenhouse gas (GHG) emissions](https://en.wikipedia.org/wiki/Greenhouse_gas_emissions \"Greenhouse gas emissions\") caused by an individual, event, organization, service, place or product, expressed as [carbon dioxide equivalent](https://en.wikipedia.org/wiki/Carbon_Dioxide_Equivalent \"Carbon Dioxide Equivalent\") (CO2e). Greenhouse gases, including the carbon-containing gases [carbon dioxide](https://en.wikipedia.org/wiki/Carbon_dioxide \"Carbon dioxide\") and [methane](https://en.wikipedia.org/wiki/Methane \"Methane\"), can be emitted through the burning of [fossil fuels](https://en.wikipedia.org/wiki/Fossil_fuels \"Fossil fuels\"), land clearance and the production and consumption of food, manufactured goods, materials, wood, roads, buildings, transportation, and other services.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CodeCarbon](https://codecarbon.io/)\n",
    "\n",
    "**CodeCarbon is a lightweight software package that seamlessly integrates into your Python codebase. It estimates the amount of carbon dioxide (CO2) produced by the cloud or personal computing resources used to execute the code.**\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "\n",
    "tracker.start()\n",
    "expensive_computing_function_here()\n",
    "tracker.stop()\n",
    "\n",
    "```\n",
    "\n",
    "**Let us now train a model and generate an emisson report.** üå±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:59:30] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 14:59:30] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 14:59:31] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 14:59:31] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 14:59:31] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 14:59:33] CPU Model on constant consumption mode: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz\n",
      "[codecarbon INFO @ 14:59:33] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 14:59:33]   Platform system: Windows-10-10.0.19042-SP0\n",
      "[codecarbon INFO @ 14:59:33]   Python version: 3.9.13\n",
      "[codecarbon INFO @ 14:59:33]   Available RAM : 31.749 GB\n",
      "[codecarbon INFO @ 14:59:33]   CPU count: 8\n",
      "[codecarbon INFO @ 14:59:33]   CPU model: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz\n",
      "[codecarbon INFO @ 14:59:33]   GPU count: 1\n",
      "[codecarbon INFO @ 14:59:33]   GPU model: 1 x NVIDIA GeForce MX450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "TensorFlow version: 2.10.1\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        25050     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2450)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1225500   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "\n",
      "Epoch 1/10\n",
      "235/235 [==============================] - 8s 20ms/step - loss: 0.2145 - accuracy: 0.9373\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0525 - accuracy: 0.9837\n",
      "Epoch 3/10\n",
      " 91/235 [==========>...................] - ETA: 2s - loss: 0.0365 - accuracy: 0.9888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:59:54] Energy consumed for RAM : 0.000050 kWh. RAM Power : 11.905803680419922 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94/235 [===========>..................] - ETA: 2s - loss: 0.0365 - accuracy: 0.9887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:59:54] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 14:59:54] Energy consumed for all CPUs : 0.000058 kWh. All CPUs Power : 14.0 W\n",
      "[codecarbon INFO @ 14:59:54] 0.000108 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0354 - accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0268 - accuracy: 0.9917\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0204 - accuracy: 0.9935\n",
      "Epoch 6/10\n",
      "169/235 [====================>.........] - ETA: 1s - loss: 0.0159 - accuracy: 0.9949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:00:09] Energy consumed for RAM : 0.000099 kWh. RAM Power : 11.905803680419922 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/235 [====================>.........] - ETA: 1s - loss: 0.0159 - accuracy: 0.9949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:00:09] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 15:00:09] Energy consumed for all CPUs : 0.000117 kWh. All CPUs Power : 14.0 W\n",
      "[codecarbon INFO @ 15:00:09] 0.000216 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0162 - accuracy: 0.9948\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0124 - accuracy: 0.9963\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0109 - accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 10/10\n",
      " 13/235 [>.............................] - ETA: 4s - loss: 0.0086 - accuracy: 0.9964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:00:24] Energy consumed for RAM : 0.000149 kWh. RAM Power : 11.905803680419922 W\n",
      "[codecarbon INFO @ 15:00:24] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 15:00:24] Energy consumed for all CPUs : 0.000175 kWh. All CPUs Power : 14.0 W\n",
      "[codecarbon INFO @ 15:00:24] 0.000324 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0075 - accuracy: 0.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:00:28] Energy consumed for RAM : 0.000163 kWh. RAM Power : 11.905803680419922 W\n",
      "[codecarbon INFO @ 15:00:28] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 15:00:28] Energy consumed for all CPUs : 0.000192 kWh. All CPUs Power : 14.0 W\n",
      "[codecarbon INFO @ 15:00:28] 0.000354 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.9908\n",
      "Final Loss: 0.03.\n",
      "Final Performance: 99.08 %.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "train_images=x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "test_images=x_test.reshape(x_test.shape[0], 28, 28 ,1) \n",
    "                                            \n",
    "train_labels=tf.keras.utils.to_categorical(y_train)\n",
    "test_labels=tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(20, (5,5), padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(50, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "\n",
    "print('Training...\\n')\n",
    "\n",
    "tracker.start()\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    batch_size=256, verbose=1)\n",
    "\n",
    "tracker.stop()\n",
    "\n",
    "print('\\nEvaluating...\\n')\n",
    "test_loss_score, test_acc_score = model.evaluate(test_images, test_labels)\n",
    "print(f'Final Loss: {round(test_loss_score, 2)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Emission Report Generator()`\n",
    "\n",
    "**First, let's import all the data we find relevant from the CSV report generated by the CodeCarbon `tracker()` method. We are also importing some details of the model in question from another CSV file.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'emissions_CIFAR_CNN_GPU.csv')\n",
    "df = df.drop(['timestamp', 'project_name', 'run_id'], axis=1) # Drop some columns the report does not use\n",
    "\n",
    "precision = 6 # number of digits after the decimal point\n",
    "\n",
    "duration = df['duration'][0]\n",
    "emissions = df['emissions'][0]\n",
    "emissions_rate = df['emissions_rate'][0]\n",
    "cpu_power = df['cpu_power'][0]\n",
    "gpu_power = df['gpu_power'][0]\n",
    "ram_power = df['ram_power'][0]\n",
    "cpu_energy = df['cpu_energy'][0]\n",
    "gpu_energy = df['gpu_energy'][0]\n",
    "ram_energy = df['ram_energy'][0]\n",
    "energy_consumed = df['energy_consumed'][0]\n",
    "country_name = df['country_name'][0]\n",
    "country_iso_code = df['country_iso_code'][0]\n",
    "region = df['region'][0]\n",
    "cloud_provider = df['cloud_provider'][0]\n",
    "cloud_region = df['cloud_region'][0]\n",
    "os = df['os'][0]\n",
    "python_version = df['python_version'][0]\n",
    "cpu_count = df['cpu_count'][0]\n",
    "cpu_model = df['cpu_model'][0]\n",
    "gpu_count = df['gpu_count'][0]\n",
    "gpu_model = df['gpu_model'][0]\n",
    "ram_total_size = df['ram_total_size'][0]\n",
    "tracking_mode = df['tracking_mode'][0]\n",
    "on_cloud = df['on_cloud'][0]\n",
    "\n",
    "# Simple model report\n",
    "df = pd.read_csv('model_details.csv')\n",
    "\n",
    "who_is_responsible = df['who_is_responsible'][0]\n",
    "model_specification = df['model_specification'][0]\n",
    "intended_use = df['intended_use'][0]\n",
    "dataset = df['dataset'][0]\n",
    "licensee = df['license'][0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we simply use the information from the emission report files to fill a `template.md` card.** üìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='CO2 report (CIFAR_CNN).md' target='_blank'>CO2 report (CIFAR_CNN).md</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "today_date = today.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "with open('CO2 report (CIFAR_CNN).md', 'w+') as fp:\n",
    "    fp.write(f'''# $CO_{2}$ Emission Report\n",
    "\n",
    "Generated at: _{today_date}_\n",
    "\n",
    "## CARBON FOOTPRINT\n",
    "\n",
    "A carbon footprint is the total greenhouse gas (GHG) emissions caused by an individual, event, organization, service, place or product, expressed as carbon dioxide equivalent ($CO_{2}e$). Greenhouse gases, including the carbon-containing gases carbon dioxide and methane , can be emitted through the burning of fossil fuels , land clearance, and the production and consumption of food, manufactured goods, materials, wood, roads, buildings, transportation, and other services.\n",
    "\n",
    "Modern AI models can consume a massive amount of energy during their training and fine-tuning phase, and these energy requirements are growing at a breathtaking rate. Researchers from the University of Massachusetts [[1](references)], Amherst, conducted a life cycle analysis for training several typical big AI models in a recent publication. They discovered that the procedure may produce almost $626,000$ pounds of $CO_{2}$ equivalent.\n",
    "\n",
    "## $CO_{2}$ Emission Report with CodeCarbon\n",
    "\n",
    "A $CO_{2}$ Emission Report is a simple transparency tool to help developers make public (and thus become accountable) the $CO_{2}$ production of an ML model.\n",
    "\n",
    "This report is made possible by CodeCarbon [[2](references)] [[3](references)] [[4](references)] a lightweight software package that seamlessly integrates into your Python codebase. It estimates the amount of carbon dioxide ($CO_{2}$) produced by the cloud or personal computing resources used to execute the code.\n",
    "\n",
    "## HOW TO USE CODECARBON\n",
    "\n",
    "One can use the Code Carbon library by simply installing its dependencies with a `pip install codecarbon`, a using its tracker function to register the energy consumption of some costly computation.\n",
    "\n",
    "```python\n",
    "\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "expensive_computing_function_here()\n",
    "tracker.stop()\n",
    "\n",
    "```\n",
    "\n",
    "## MODEL DETAILS\n",
    "\n",
    "- {who_is_responsible}\n",
    "- {model_specification}\n",
    "- {intended_use}\n",
    "- {dataset}\n",
    "- {licensee}\n",
    "\n",
    "## $CO_{2}$ Emission Results\n",
    "\n",
    "|**Duration (Seconds)**|**Emission (KgCO2)**|**Emission Rate (KtCO2/Year)**|**CPU Power (Watts)**|\n",
    "|--------------------------------|-------------------------------------|------------------------------------|--------------------------------|\n",
    "| {round(duration, precision)}|{round(emissions, precision)}|{round(emissions_rate, precision)}|{round(cpu_power, precision)}|\n",
    "|**GPU Power (Watts)**|**RAMPower (Watts)**|**Power Consumption (CPU - kWh)**|**Power Consumption (GPU - kWh)**|\n",
    "|{round(gpu_power, precision)}| {round(ram_power, precision)}|{round(cpu_energy, precision)}|{round(gpu_energy, precision)}|\n",
    "|**Power Consumption (RAM - kWh)**|**Total Consumption (kWh)**|**Country**| **ISO**|\n",
    "|{round(ram_energy, precision)}|{round(energy_consumed, precision)}|{country_name}|{country_iso_code}|\n",
    "|**Region**| **Cloud Provider**| **Provider's Region**|**OS**|\n",
    "|{region}| {cloud_provider}| {cloud_region}|{os}|\n",
    "|**Python Version**| **No. of Processors**|**Provider's CPU Model**| **No. of GPUs**|\n",
    "|{python_version}|{cpu_count}|{cpu_model}|{gpu_count}|\n",
    "|**GPU Model**|**RAM Memory Size (GB)**| **Tracking Mode**|**Cloud-Processed**|\n",
    "|{gpu_model}| {ram_total_size}|{tracking_mode}| {on_cloud}|\n",
    "\n",
    "## REFERENCES\n",
    "\n",
    "[1] Karen Hao. Training a single ai model can emit as much carbon as five cars in their lifetimes. _MIT technology Review_, 2019.\n",
    "\n",
    "[2] Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, and Thomas Dandres. Quantifying the carbon emissions of machine learning. _Workshop on Tackling Climate Change with Machine Learning at NeurIPS 2019_, 2019.\n",
    "\n",
    "[3] Kadan Lottick, Silvia Susai, Sorelle A. Friedler, and Jonathan P. Wilson. Energy usage reports: Environmental awareness as part of algorithmicaccountability. _Workshop on Tackling Climate Change with Machine Learning at NeurIPS 2019_, 2019.\n",
    "\n",
    "[4] Victor Schmidt, Kamal Goyal, Aditya Joshi, Boris Feld, Liam Conell, Nikolas Laskaris, Doug Blank, Jonathan Wilson, Sorelle Friedler, and Sasha Luccioni. CodeCarbon: _Estimate and Track Carbon Emissions from Machine Learning Computing_, 2021.\n",
    "''')\n",
    "    fp.close()\n",
    "    \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(f\"<a href='CO2 report (CIFAR_CNN).md' target='_blank'>CO2 report (CIFAR_CNN).md</a>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other available options for CO2 emission tracking are [Eco2AI](https://github.com/sb-ai-lab/Eco2AI), which has a pretty similar interface and user experience then CodeCarbon.** üôÉ\n",
    "\n",
    "----\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
