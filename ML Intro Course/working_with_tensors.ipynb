{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with `TENSORS`\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n",
    "\n",
    "**Tensors are a specialized data structure that are very similar to arrays and matrices. In mathematics, a _tensor_ is an algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors.**\n",
    "\n",
    "![tensors](https://images.nvidia.com/aem-dam/Solutions/Data-Center/tesla-t4/Turing-Tensor-Core_30fps_FINAL_736x414.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensors can be created from:**\n",
    "\n",
    "- _directly from data._\n",
    "- _from NumPy arrays._\n",
    "- _form another Tensor._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(type(data), type(x_data))\n",
    "display(x_data)\n",
    "\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(type(np_array), type(x_np))\n",
    "display(x_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.ones_like`: _creates a tensor of 'ones' that retains the properties of some reference._\n",
    "- `torch.rand_like`: _creates a tensor of random numbers that retains the properties of some reference._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7862, 0.0438],\n",
      "        [0.4974, 0.1137]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f'Ones Tensor: \\n {x_ones} \\n')\n",
    "\n",
    "# dtype=torch.float overrides the datatype of x_data\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f'Random Tensor: \\n {x_rand} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bellow, the variable `shape` is a tuple of tensor dimensions. It determines the dimensionality of the output tensor.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.7326, 0.1595, 0.1310],\n",
      "        [0.3994, 0.3787, 0.3583],\n",
      "        [0.3493, 0.1248, 0.4439]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (3, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'Random Tensor: \\n {rand_tensor} \\n')\n",
    "print(f'Ones Tensor: \\n {ones_tensor} \\n')\n",
    "print(f'Zeros Tensor: \\n {zeros_tensor}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Like vectors and matrices, you can calculate arithmetic operations with tensors.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of rand_tensor with itself: \n",
      " [[0.6461566  0.19364569 0.21128307]\n",
      " [0.5689914  0.2518838  0.34704387]\n",
      " [0.46077016 0.15842146 0.28752598]] \n",
      "\n",
      "The element-wise product of rand_tensor with zeros_tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n",
      "rand_tensor plus ones_tensor: \n",
      " tensor([[1.7326, 1.1595, 1.1310],\n",
      "        [1.3994, 1.3787, 1.3583],\n",
      "        [1.3493, 1.1248, 1.4439]]) \n",
      "\n",
      "Matrix multiplication between ones_tensor with itself: \n",
      " tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]]) \n",
      "\n",
      "Summation of all elements in ones_tensor: \n",
      " 9.0 \n",
      "\n",
      "Adding a constant to all elements in rand_tensor: \n",
      " tensor([[3.7326, 3.1595, 3.1310],\n",
      "        [3.3994, 3.3787, 3.3583],\n",
      "        [3.3493, 3.1248, 3.4439]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'Dot product of rand_tensor with itself: \\n {np.dot(rand_tensor, rand_tensor)} \\n')\n",
    "\n",
    "# rand_tensor.mul(zeros_tensor)\n",
    "print(\n",
    "    f'The element-wise product of rand_tensor with zeros_tensor: \\n {rand_tensor * zeros_tensor} \\n')\n",
    "\n",
    "print(f'rand_tensor plus ones_tensor: \\n {rand_tensor + ones_tensor} \\n')\n",
    "\n",
    "# ones_tensor.matmul(ones_tensor.T) is equivalent\n",
    "print(\n",
    "    f'Matrix multiplication between ones_tensor with itself: \\n {ones_tensor @ ones_tensor.T} \\n')\n",
    "\n",
    "print(\n",
    "    f'Summation of all elements in ones_tensor: \\n {ones_tensor.sum().item()} \\n')\n",
    "\n",
    "print(\n",
    "    f'Adding a constant to all elements in rand_tensor: \\n {rand_tensor.add_(3)} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described [here](https://pytorch.org/docs/stable/torch.html).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor attributes describe their shape, datatype, and the device on which they are stored.**\n",
    "\n",
    "- _By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using `.to` method (after checking for GPU availability)._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([5, 5])\n",
      "\n",
      "Datatype of tensor: torch.float32\n",
      "\n",
      "Device tensor is stored on: cpu\n",
      "\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of tensor: {rand_tensor.shape}\\n')\n",
    "print(f'Datatype of tensor: {rand_tensor.dtype}\\n')\n",
    "print(f'Device tensor is stored on: {rand_tensor.device}\\n')\n",
    "if torch.cuda.is_available():\n",
    "    gpu_rand_tensor = rand_tensor.to(\"cuda\")\n",
    "print(f'Device tensor is stored on: {gpu_rand_tensor.device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can use `torch.cat` to concatenate a sequence of tensors along a given dimension. See also `torch.stack`, another tensor joining op that is subtly different from `torch.cat`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated tensors: \n",
      "tensor([[0.5219, 0.0954, 0.3577, 0.8004, 0.5817],\n",
      "        [0.5285, 0.5968, 0.7817, 0.4855, 0.1202],\n",
      "        [0.2983, 0.6091, 0.4962, 0.1911, 0.0287],\n",
      "        [0.4701, 0.5074, 0.6865, 0.7861, 0.5892],\n",
      "        [0.4008, 0.0280, 0.1837, 0.8371, 0.7738],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "\n",
      "Staked tensors: \n",
      "tensor([[[0.5219, 0.0954, 0.3577, 0.8004, 0.5817],\n",
      "         [0.5285, 0.5968, 0.7817, 0.4855, 0.1202],\n",
      "         [0.2983, 0.6091, 0.4962, 0.1911, 0.0287],\n",
      "         [0.4701, 0.5074, 0.6865, 0.7861, 0.5892],\n",
      "         [0.4008, 0.0280, 0.1837, 0.8371, 0.7738]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_tensor = torch.cat([rand_tensor, ones_tensor, zeros_tensor], dim=0)\n",
    "print(f'Concatenated tensors: \\n{join_tensor}\\n')\n",
    "join_tensor = torch.stack([rand_tensor, ones_tensor, zeros_tensor], dim=0)\n",
    "print(f'Staked tensors: \\n{join_tensor}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a full and comprehensive tutorial on tensors, visit the [Introduction to Tensors](https://www.tensorflow.org/guide/tensor) tutorial.**\n",
    "\n",
    "---\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
