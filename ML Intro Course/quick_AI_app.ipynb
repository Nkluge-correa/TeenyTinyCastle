{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI Applications with `Gradio`\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n",
    "\n",
    "**In this repository, you will find examples of to create simple interfaces for things like, for example, [sentiment analysis](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/bbe9c0a77499fa68de7c6d53bf5ef7e0b43a25e0/ML%20Explainability/NLP%20Interpreter%20(en)/senti_dash_en.py), and even a [playground for HuggingFace language models](https://github.com/Nkluge-correa/teeny-tiny_castle/tree/master/ML%20Explainability/NLP%20Playgroung). These interfaces can be used to create ML applications since all of them use things like `Flask` for the backend, and bootstrap and CSS for the front end part.**\n",
    "\n",
    "**However, there are simpler ways to create demo ML apps. And one of the simpler ways is `Gradio`.**\n",
    "\n",
    "**[Gradio](https://gradio.app/) is a free and open-source Python library that allows you to develop an easy-to-use customizable component demo for your machine learning model that anyone can use anywhere. Gradio integrates with the most popular Python libraries used for ML and Data Science, including [Scikit-learn](https://scikit-learn.org/stable/), [PyTorch](https://pytorch.org/), [NumPy](https://numpy.org/), [seaborn](https://seaborn.pydata.org/), [pandas](https://pandas.pydata.org/), [TensorFlow](https://www.tensorflow.org/), and many others.**\n",
    "\n",
    "![gradio-image](https://pbs.twimg.com/profile_images/1526964416834510848/Njy4Kh2q_400x400.jpg)\n",
    "\n",
    "**Let's first create an application to [recognize digits](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/bbe9c0a77499fa68de7c6d53bf5ef7e0b43a25e0/ML%20Intro%20Course/MNIST_digit.ipynb), one of the first tasks in DL that we explore in our mini course.**\n",
    "\n",
    "**For this application, instead of training a dense feed-forward model, we will train a convolutional neural network (CNN), since this is the standard in computer vision applications. You can find other examples of how to build CNNs on [this](https://github.com/Nkluge-correa/teeny-tiny_castle/blob/bbe9c0a77499fa68de7c6d53bf5ef7e0b43a25e0/ML%20Explainability/CV%20Interpreter/CNN_model_maker.ipynb) notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "Training Set Size: \n",
      "(60000, 28, 28)\n",
      "Test Set Size: \n",
      "(10000, 28, 28)\n",
      "Version:  2.10.0\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        25050     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2450)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1225500   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "\n",
      "N¬∫ GPUs Available:  1\n",
      "Epoch 1/10\n",
      "235/235 - 8s - loss: 0.2166 - accuracy: 0.9345 - 8s/epoch - 35ms/step\n",
      "Epoch 2/10\n",
      "235/235 - 4s - loss: 0.0533 - accuracy: 0.9838 - 4s/epoch - 17ms/step\n",
      "Epoch 3/10\n",
      "235/235 - 4s - loss: 0.0364 - accuracy: 0.9886 - 4s/epoch - 17ms/step\n",
      "Epoch 4/10\n",
      "235/235 - 4s - loss: 0.0266 - accuracy: 0.9916 - 4s/epoch - 17ms/step\n",
      "Epoch 5/10\n",
      "235/235 - 4s - loss: 0.0201 - accuracy: 0.9937 - 4s/epoch - 17ms/step\n",
      "Epoch 6/10\n",
      "235/235 - 4s - loss: 0.0151 - accuracy: 0.9950 - 4s/epoch - 17ms/step\n",
      "Epoch 7/10\n",
      "235/235 - 4s - loss: 0.0129 - accuracy: 0.9959 - 4s/epoch - 17ms/step\n",
      "Epoch 8/10\n",
      "235/235 - 4s - loss: 0.0106 - accuracy: 0.9967 - 4s/epoch - 17ms/step\n",
      "Epoch 9/10\n",
      "235/235 - 4s - loss: 0.0084 - accuracy: 0.9972 - 4s/epoch - 19ms/step\n",
      "Epoch 10/10\n",
      "235/235 - 4s - loss: 0.0064 - accuracy: 0.9980 - 4s/epoch - 18ms/step\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9915\n",
      "Final Loss: 0.03.\n",
      "Final Performance: 99.15 %.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "train_images=x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "test_images=x_test.reshape(x_test.shape[0], 28, 28 ,1) \n",
    "                                            \n",
    "train_labels=tf.keras.utils.to_categorical(y_train)\n",
    "test_labels=tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "print('Training Set Size: '), print(x_train.shape)\n",
    "print('Test Set Size: '), print(x_test.shape)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(20, (5,5), padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "    keras.layers.Conv2D(50, (5,5), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(500, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "\n",
    "print('Training...\\n')\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    batch_size=256, verbose=2)\n",
    "print('\\nEvaluating...\\n')\n",
    "test_loss_score, test_acc_score = model.evaluate(test_images, test_labels)\n",
    "print(f'Final Loss: {round(test_loss_score, 2)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')\n",
    "model.save('models\\digit_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With our trained and saved model, creating an application with gradio takes no more than a little more than 20 lines of code. You can style certain components with HTML, Markdown, and CSS. Applications created with gradio can even be hosted on the `gradio.app` for 72 hours, free of charge. Just use launch the application with the `share` argument equal to `True` (`demo.launch(share=True)`).**\n",
    "\n",
    "**Permanent hosting can be easily done through the [HuggingFace Spaces](https://www.huggingface.co/spaces), or any PaaS (Platforms as a service) you wish to use, like [Heroku](https://heroku.com/) or [Render](https://render.com/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models\\digit_classifier.h5')\n",
    "classes = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "def predict(img):\n",
    "\tprediction = model.predict(img.reshape(1, 28, 28, 1), verbose=0).tolist()[0]\n",
    "\treturn {classes[i]: prediction[i] for i in range(10)}\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "title = \"Digit Classifier - By Teeny-Tiny Castle üè∞\"\n",
    "\n",
    "head = (\n",
    "  \"<center>\"\n",
    "  \"<img src='https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png' width=400>\"\n",
    "  \"This model was trained to classify numbers (from 0 to 9). To test it, write your number in the space provided.\"\n",
    "  \"</center>\"\n",
    ")\n",
    "\n",
    "ref = \"Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\"\n",
    "\n",
    "\n",
    "demo = gr.Interface(fn=predict, \n",
    "             inputs=\"sketchpad\",\n",
    "             outputs=gr.Label(num_top_classes=3),\n",
    "             allow_flagging=\"never\",\n",
    "             title=title, \n",
    "             description=head, \n",
    "             article=ref)\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can even use Gradio to create applications that are not ML-based. For example, below we show you how to create a closed-domain chatbot with a small number of answers and questions (_a basic rules-based system that performs n-gram search_). To see the full implementation of this bot, go to [this](https://github.com/Nkluge-correa/Aira-EXPERT) link. and to chat with `Ai.ra` go to [this](https://aira-expert.onrender.com/) link!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "import urllib.request\n",
    "import gradio as gr\n",
    "import itertools\n",
    "import unidecode\n",
    "import string\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    'https://drive.google.com/uc?export=download&id=1TXD41vfqNWA6UNDQ73WhtJdZivCJatn-', \n",
    "    'bot__questions_tags.json'\n",
    ")\n",
    "\n",
    "answers = ['Hello! My name is Ai.ra, and I am an artificial intelligence (AI). More specifically, I am an NLP (Natural Language Processing) model trained in conversation (a chatbot!).',\n",
    " 'You can ask me things about \"Artificial Intelligence,\" \"Machine Learning,\" \"AI Safety,\" or \"AI Ethics.\"',\n",
    " \"I don't have that kind of property hahaha I am software!\",\n",
    " \"AIRES (AI Robotics Ethics Society) is a society focused on educating the leaders and developers of tomorrow's Artificial Intelligence (AI) to ensure that AI is created ethically and responsibly.\",\n",
    " 'Aron Hui is the president/founder of AIRES.',\n",
    " 'What \"intelligence\" is, remains an open question. However, not to leave you in the lurch, I will define \"intelligence\" as follows: \"Intelligence is the ability of an agent to achieve goals in a wide range of environments.\"',\n",
    " 'There is no consensus in the literature on what \"AI\" is (a corollary of not having a robust definition of what \"intelligence\\'\\' is). However, we can say that AI is the intelligence demonstrated by machines, as opposed to the natural intelligence possessed by animals and humans.',\n",
    " 'General Intelligence, or Universal Intelligence, can be defined as the ability to efficiently achieve goals in a wide range of domains.',\n",
    " 'GOFAI (\"good-old-fashioned-ai\"), or symbolic artificial intelligence, is the term used to refer to methods of developing AI systems based on high-level symbolic (interpretable) representations, logic, and search.',\n",
    " 'A multi-agent system (MAS \"Multi-Agent Systems\") is a computer system composed of multiple interacting intelligent agents.',\n",
    " 'Machine Learning (ML) is a field of research dedicated to understanding and building methods that \"learn\", i.e., methods that use information/data to improve performance on some tasks.']\n",
    "\n",
    "\n",
    "with open('bot__questions_tags.json') as json_file:\n",
    "    dictionary = json.load(json_file)\n",
    "\n",
    "\n",
    "def generate_ngrams(text, WordsToCombine):\n",
    "    words = text.split()\n",
    "    output = []\n",
    "    for i in range(len(words) - WordsToCombine+1):\n",
    "        output.append(words[i:i+WordsToCombine])\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_keys(text, WordsToCombine):\n",
    "    gram = generate_ngrams(text, WordsToCombine)\n",
    "    sentences = []\n",
    "    for i in range(0, len(gram)):\n",
    "        sentence = ' '.join(gram[i])\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    history = history or []\n",
    "    message = message.lower()\n",
    "    sentences = []\n",
    "    values = []\n",
    "    new_text = message.translate(str.maketrans('', '', string.punctuation))\n",
    "    new_text = unidecode.unidecode(new_text)\n",
    "\n",
    "    if len(new_text.split()) == 1:\n",
    "        if new_text in dictionary.keys():\n",
    "            l = [dictionary[new_text]] * 100\n",
    "            values.append(l)\n",
    "        new_text = new_text + ' ' + new_text\n",
    "\n",
    "    elif len(new_text.split()) != 1:\n",
    "        if new_text in dictionary.keys():\n",
    "            l = [dictionary[new_text]] * 100\n",
    "            values.append(l)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    for i in range(1, len(new_text.split()) + 1):\n",
    "        sentence = make_keys(new_text, i)\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    for i in range(0, len(sentences)):\n",
    "        attention = sentences[i]\n",
    "        for i in range(0, len(attention)):\n",
    "            if attention[i] in dictionary.keys():\n",
    "                l = [dictionary[attention[i]]] * i\n",
    "                values.append(l)\n",
    "\n",
    "    if len(values) == 0:\n",
    "        bot_input_ids = \"I'm sorry, either I didn't understand the question, or it is not part of my domain of expertise... :( Try asking it in another way or using other words. Maybe then I can help you!\"\n",
    "        history.append((message, bot_input_ids))\n",
    "        return history, history\n",
    "\n",
    "    elif len(values) != 0:\n",
    "        values = list(itertools.chain(*values))\n",
    "        prediction = mode(values)\n",
    "        bot_input_ids = answers[int(prediction)-1]\n",
    "        history.append((message, bot_input_ids))\n",
    "        return history, history\n",
    "\n",
    "title = \"Basic Chatbot - By Teeny-Tiny Castle üè∞\"\n",
    "\n",
    "head = (\n",
    "  \"<center>\"\n",
    "  \"<img src='https://d2vrvpw63099lz.cloudfront.net/do-i-need-a-chatbot/header-chat-box.png' width=400>\"\n",
    "  \"This is an example of a rulses-based close domain chatbot. It knows a couple of awensers to questions related to AI.\"\n",
    "  \"<br>\"\n",
    "  \"</center>\"\n",
    ")\n",
    "\n",
    "ref = \" To see its full version (ML style) of this bot, go to [this](https://aira-expert.onrender.com/) link.\"\n",
    "\n",
    "chatbot = gr.Chatbot().style(color_map=(\"green\", \"pink\"))\n",
    "demo = gr.Interface(\n",
    "    chat,\n",
    "    [\"text\", \"state\"],\n",
    "    [chatbot, \"state\"],\n",
    "    allow_flagging=\"never\",\n",
    "    title=title, \n",
    "    description=head, \n",
    "    article=ref\n",
    ")\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now you know how to create simple AI applications to show and share with your friends and colleagues!** ü§ñ\n",
    "\n",
    "---\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
