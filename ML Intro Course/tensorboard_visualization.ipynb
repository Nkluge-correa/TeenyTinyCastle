{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the performance of deep learning models with `Tensorboard`\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n",
    "\n",
    "**There are various tools for measuring the performance of a deep learning model, like [Neptune AI](https://www.google.com/aclk?sa=l&ai=DChcSEwj1xIKopMn5AhVB5VwKHYIcAVwYABAAGgJjZQ&sig=AOD64_3vHRiEXqPZnFvdKHZez_oorbqA6w&q&adurl&ved=2ahUKEwjv6PynpMn5AhXZgpUCHR1CCXUQ0Qx6BAgCEAE) and [Weights and Biases](https://wandb.ai/site). In this notebook, we’ll teach how to use _TensorFlow’s_ open-source _visualization toolkit: [TensorBoard](https://www.tensorflow.org/tensorboard)_.**\n",
    "\n",
    "![tensordboard](https://www.tensorflow.org/tensorboard/images/tensorboard.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you don't have tensorboard installed, you can quickly get this package by:\n",
    "\n",
    "- `pip install tensorboard` in your terminal/CLI;\n",
    "- `%pip install tensorboard` in a code cell of your jupyter notebook;\n",
    "- `!pip install tensorboard` in a code cell of your colab notebook.\n",
    "\n",
    "_Now, you just need to load the tensorboard into your Notebook and set a log directory (this directory is where tensorboard will store all the logs from your ML experiments._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "log_folder = 'logs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_If you want to reload the tensorboard from before:_\n",
    "\n",
    "- `%reload_ext tensorboard`\n",
    "\n",
    "_If you want to clear the current logs to write new ones:_\n",
    "\n",
    "- `rm -rf logs`\n",
    "\n",
    "_If you want to add a timestamp to your logs:_\n",
    "\n",
    "- `log_folder = 'logs/fit/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's use the IMDB sentiment-analysis dataset for the sake of this explanation.**\n",
    "\n",
    "![IMDB](https://upload.wikimedia.org/wikipedia/commons/6/69/IMDB_Logo_2016.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embed (Embedding)           (None, 500, 128)          256000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 494, 32)           28704     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 98, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 92, 32)            7200      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "vocabulary = 2000 # Number of words to consider as features.\n",
    "max_len = 500 # Cuts off texts after this number of words (among max_features most common words).\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocabulary)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Embedding(vocabulary, 128,\n",
    "                            input_length=max_len,\n",
    "                            name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer='rmsprop',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a model to track, you need to set your tensorboard callback during the model’s fit method (this is the method responsible for logging events such as **activation histograms,** **metrics plots,** **training graph visualizations**.).\n",
    "\n",
    "Parameters the **TensorBoard callback** takes:\n",
    "\n",
    "- **log_dir**: where to store the logs;\n",
    "- **histogram_freq**: the frequency at which to compute activation and weight histograms for layers of the model (_0 means that histograms will not be computed_);\n",
    "- **write_graph**: `True` will make graph be visualized in TensorBoard;\n",
    "- **write_images**: `True` will make model weights be visualized as an image in TensorBoard;\n",
    "- **update_freq**: determines how **losses** and **metrics** are written to TensorBoard (_when set to `epoch` they are written after every epoch_);\n",
    "- **profile_batch**: determines which batches will be profiled (_by default, the second batch is profiled. Setting profile_batch to 0 disables profiling_);\n",
    "- **embeddings_freq**: the frequency at which the embedding layers will be visualized (_setting to 0 means that the embeddings will not be visualized_).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.10.0\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Epoch 1/20\n",
      "157/157 [==============================] - 12s 41ms/step - loss: 0.6486 - acc: 0.6292 - val_loss: 0.4802 - val_acc: 0.7848\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.4595 - acc: 0.8449 - val_loss: 0.4489 - val_acc: 0.8566\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3901 - acc: 0.8737 - val_loss: 0.4749 - val_acc: 0.8576\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.3513 - acc: 0.8941 - val_loss: 0.5078 - val_acc: 0.8698\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 8s 54ms/step - loss: 0.2954 - acc: 0.9158 - val_loss: 0.5811 - val_acc: 0.8692\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 9s 59ms/step - loss: 0.2681 - acc: 0.9270 - val_loss: 0.5944 - val_acc: 0.8656\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.2125 - acc: 0.9495 - val_loss: 0.8601 - val_acc: 0.8446\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 8s 54ms/step - loss: 0.1772 - acc: 0.9678 - val_loss: 0.7110 - val_acc: 0.8692\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.1446 - acc: 0.9761 - val_loss: 0.7942 - val_acc: 0.8650\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.1320 - acc: 0.9819 - val_loss: 0.8803 - val_acc: 0.8658\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.1116 - acc: 0.9870 - val_loss: 1.2987 - val_acc: 0.8380\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 11s 68ms/step - loss: 0.1038 - acc: 0.9891 - val_loss: 1.0048 - val_acc: 0.8656\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 11s 73ms/step - loss: 0.0974 - acc: 0.9901 - val_loss: 1.4846 - val_acc: 0.8322\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 11s 69ms/step - loss: 0.0963 - acc: 0.9902 - val_loss: 2.1075 - val_acc: 0.7874\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 10s 66ms/step - loss: 0.0938 - acc: 0.9918 - val_loss: 1.1725 - val_acc: 0.8624\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 11s 68ms/step - loss: 0.0917 - acc: 0.9923 - val_loss: 1.2803 - val_acc: 0.8536\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 12s 74ms/step - loss: 0.0949 - acc: 0.9923 - val_loss: 1.1738 - val_acc: 0.8648\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 9s 55ms/step - loss: 0.0984 - acc: 0.9897 - val_loss: 1.2023 - val_acc: 0.8638\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.0925 - acc: 0.9916 - val_loss: 1.1966 - val_acc: 0.8624\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 10s 65ms/step - loss: 0.0952 - acc: 0.9916 - val_loss: 1.2122 - val_acc: 0.8634\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 1.2251 - acc: 0.8618\n",
      "Final Loss: 1.23.\n",
      "Final Performance: 86.18 %.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = tf.keras.callbacks.TensorBoard(log_dir=log_folder,\n",
    "                                           histogram_freq=1,\n",
    "                                           write_graph=True,\n",
    "                                           write_images=True,\n",
    "                                           update_freq='epoch',\n",
    "                                           profile_batch=2,\n",
    "                                           embeddings_freq=1)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split= 0.2,\n",
    "                    callbacks=[callbacks],\n",
    "                    verbose=1\n",
    "                    )\n",
    "test_loss_score, test_acc_score = model.evaluate(x_test, y_test)\n",
    "print(f'Final Loss: {round(test_loss_score, 2)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic TensorBoard Guide\n",
    "\n",
    "- **The Scalars tab shows changes in the loss and metrics over the epochs. It can be used to track other scalar values such as learning rate and training speed.**\n",
    "- **The images tab shows the weights. Adjusting the slider displays the weights at various epochs.**\n",
    "- **The graph tab shows your model’s layers. You can use this to check if the architecture of the model looks as intended.**\n",
    "- **The distribution tab shows the distribution of tensors (_the distribution of the weights and biases over each epoch_)**.\n",
    "- **The histograms tab show the distribution of tensors over time.**\n",
    "\n",
    "**If you installed TensorBoard via pip, you can launch it via the command line:**\n",
    "\n",
    "> `tensorboard --logdir=logs`\n",
    "\n",
    "**On a Notebook, you can launch it using:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs (started 0:01:46 ago; pid 14840)\n",
      "  - port 6006: logdir logs (started 0:03:43 ago; pid 15496)\n",
      "  - port 6006: logdir logs (started 0:01:26 ago; pid 23124)\n",
      "Selecting TensorBoard with logdir logs (started 0:01:26 ago; port 6006, pid 23124).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f9a815a120b2f236\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f9a815a120b2f236\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "notebook.list() \n",
    "notebook.display(port=6006, height=1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
