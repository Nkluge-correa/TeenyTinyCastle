{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Hyperparameter optimization with `Hyperopt` and `Hyperas`\n","\n","Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n","\n","Many seemingly arbitrary decisions must be made when developing a deep-learning model, including: What number of layers should you use? How many filters or units should each layer contain? Should you choose a different function or use `ReLU` as an activation function? How much `dropout` ought you to employ? These architecture-level parameters are therefore referred to as hyperparameters.\n","\n","In actual use, skilled hyperparameter-tuning engineers and researchers develop intuition over time about what choices work and don't work when it comes to these choices. However, there are no set guidelines.\n","\n","As a result, you must automatically, methodically, and ethically explore the space of potential decisions. You must empirically search the architecture space to identify the best options. The study of automatic hyperparameter optimization focuses on this.\n","\n","![hyper_optimization](https://miro.medium.com/max/1142/1*5mStLTnIxsANpOHSwAFJhg.png)\n","\n","And for models built using Keras, we can use `Hyperopt` and `Hyperas` to automatize this work.\n","\n","> _[Hyperas](https://github.com/maxpumperla/hyperas) brings fast experimentation with Keras and hyperparameter optimization with Hyperopt together. It lets you use the power of hyperopt without having to learn the syntax of it. Instead, just define your keras model as you are used to, but use a simple template notation to define hyper-parameter ranges to tune._\n","\n","In this notebook, we show how to use `Hyperas` using the [Fashion MNIST dataset](https://keras.io/api/datasets/fashion_mnist/). This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images.\n","\n","![fashion_mnist](https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/3682850e-dc4d-4c07-a2c8-4e58a721b65b/f50369fd-32ea-477d-b74c-1b3f6e014122/images/screenshot.gif)\n","\n","To make Hyperes work, you have to wrap your data and model into functions as shown below and then pass them as parameters to the minimizer.\n","\n","Discrete hyper-parameters (_like units in a layer_) can be optimized by using the `choice` function; just wrap the parameters you want to optimize into double curly brackets and choose a distribution over which to run the algorithm (e.g., `{{choice([32, 64, 128])}}`). To hyper-tune continuous values (_like the learning rate_), we use the `uniform` function (e.g., `{{uniform(0, 1)}}`)."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","from hyperas import optim\n","from hyperopt import STATUS_OK\n","from hyperas.distributions import choice, uniform\n","\n","def data():\n","\n","    (x_train, y_train), (x_test,\n","                               y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","                               \n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","\n","    x_train = x_train / 255.\n","    x_test = x_test / 255.\n","\n","    y_train = tf.keras.utils.to_categorical(y_train, 10)\n","    y_test = tf.keras.utils.to_categorical(y_test, 10)\n","    return x_train, y_train, x_test, y_test\n","\n","def create_model(x_train, y_train, x_test, y_test):\n","\n","    model = tf.keras.models.Sequential()\n","\n","    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n","    model.add(tf.keras.layers.Dense({{choice([64, 128, 256])}}, activation='relu'))\n","    model.add(tf.keras.layers.Dropout({{uniform(0, 1)}}))\n","\n","    model.add(tf.keras.layers.Dense({{choice([64, 128, 256])}}, activation='relu'))\n","    model.add(tf.keras.layers.Dropout({{uniform(0, 1)}}))\n","\n","    model.add(tf.keras.layers.Dense({{choice([64, 128, 256])}}, activation='relu'))\n","    model.add(tf.keras.layers.Dropout({{uniform(0, 1)}}))\n","\n","    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","    model.compile(optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n","                loss='categorical_crossentropy',\n","                metrics=['categorical_accuracy'])\n","\n","    result = model.fit(x_train, y_train,\n","                    batch_size={{choice([32, 64, 128, 256])}}, epochs=50,\n","                    validation_split=0.2, verbose=2)\n","\n","    validation_acc = np.amax(result.history['val_categorical_accuracy']) \n","    print('Best validation acc of epoch:', validation_acc)\n","    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n","\n","x_train, y_train, x_test, y_test = data()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We call the `optim.minimize` function to run the optimization, passing our `make_model` and `data` function. You can also set the number of evaluations you want to make using the `max_evals` argument. If you are using a `notebook`, you need to pass the `notebook_name` with the name of the notebook you are running."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Imports:\n","#coding=utf-8\n","\n","try:\n","    import tensorflow as tf\n","except:\n","    pass\n","\n","try:\n","    import numpy as np\n","except:\n","    pass\n","\n","try:\n","    from hyperas import optim\n","except:\n","    pass\n","\n","try:\n","    from hyperopt import STATUS_OK\n","except:\n","    pass\n","\n","try:\n","    from hyperas.distributions import choice, uniform\n","except:\n","    pass\n","\n","try:\n","    from hyperopt import Trials, tpe\n","except:\n","    pass\n","\n","try:\n","    import tensorflow as tf\n","except:\n","    pass\n","\n","try:\n","    import plotly.graph_objects as go\n","except:\n","    pass\n","\n",">>> Hyperas search space:\n","\n","def get_space():\n","    return {\n","        'Dense': hp.choice('Dense', [64, 128, 256]),\n","        'Dropout': hp.uniform('Dropout', 0, 1),\n","        'Dense_1': hp.choice('Dense_1', [64, 128, 256]),\n","        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n","        'Dense_2': hp.choice('Dense_2', [64, 128, 256]),\n","        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n","        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n","        'batch_size': hp.choice('batch_size', [32, 64, 128, 256]),\n","    }\n","\n",">>> Data\n","  1: \n","  2: \n","  3: (x_train, y_train), (x_test,\n","  4:                            y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","  5:                            \n","  6: x_train = x_train.astype('float32')\n","  7: x_test = x_test.astype('float32')\n","  8: \n","  9: x_train = x_train / 255.\n"," 10: x_test = x_test / 255.\n"," 11: \n"," 12: y_train = tf.keras.utils.to_categorical(y_train, 10)\n"," 13: y_test = tf.keras.utils.to_categorical(y_test, 10)\n"," 14: \n"," 15: \n"," 16: \n",">>> Resulting replaced keras model:\n","\n","   1: def keras_fmin_fnct(space):\n","   2: \n","   3: \n","   4:     model = tf.keras.models.Sequential()\n","   5: \n","   6:     model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n","   7:     model.add(tf.keras.layers.Dense(space['Dense'], activation='relu'))\n","   8:     model.add(tf.keras.layers.Dropout(space['Dropout']))\n","   9: \n","  10:     model.add(tf.keras.layers.Dense(space['Dense_1'], activation='relu'))\n","  11:     model.add(tf.keras.layers.Dropout(space['Dropout_1']))\n","  12: \n","  13:     model.add(tf.keras.layers.Dense(space['Dense_2'], activation='relu'))\n","  14:     model.add(tf.keras.layers.Dropout(space['Dropout_2']))\n","  15: \n","  16:     model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","  17: \n","  18:     model.compile(optimizer=space['optimizer'],\n","  19:                 loss='categorical_crossentropy',\n","  20:                 metrics=['categorical_accuracy'])\n","  21: \n","  22:     result = model.fit(x_train, y_train,\n","  23:                     batch_size=space['batch_size'], epochs=50,\n","  24:                     validation_split=0.2, verbose=2)\n","  25: \n","  26:     validation_acc = np.amax(result.history['val_categorical_accuracy']) \n","  27:     print('Best validation acc of epoch:', validation_acc)\n","  28:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n","  29: \n","Epoch 1/50                                           \n","\n","188/188 - 3s - loss: 1.8651 - categorical_accuracy: 0.3220 - val_loss: 1.2942 - val_categorical_accuracy: 0.5658 - 3s/epoch - 18ms/step\n","\n","Epoch 2/50                                           \n","\n","188/188 - 1s - loss: 1.2863 - categorical_accuracy: 0.5153 - val_loss: 0.9006 - val_categorical_accuracy: 0.6355 - 961ms/epoch - 5ms/step\n","\n","Epoch 3/50                                           \n","\n","188/188 - 1s - loss: 1.0561 - categorical_accuracy: 0.5794 - val_loss: 0.8093 - val_categorical_accuracy: 0.6744 - 1s/epoch - 5ms/step\n","\n","Epoch 4/50                                           \n","\n","188/188 - 1s - loss: 0.9820 - categorical_accuracy: 0.6059 - val_loss: 0.7953 - val_categorical_accuracy: 0.6580 - 873ms/epoch - 5ms/step\n","\n","Epoch 5/50                                           \n","\n","188/188 - 1s - loss: 0.9271 - categorical_accuracy: 0.6438 - val_loss: 0.6931 - val_categorical_accuracy: 0.7364 - 857ms/epoch - 5ms/step\n","\n","Epoch 6/50                                           \n","\n","188/188 - 1s - loss: 0.8740 - categorical_accuracy: 0.6668 - val_loss: 0.6776 - val_categorical_accuracy: 0.7335 - 719ms/epoch - 4ms/step\n","\n","Epoch 7/50                                           \n","\n","188/188 - 1s - loss: 0.8457 - categorical_accuracy: 0.6784 - val_loss: 0.6388 - val_categorical_accuracy: 0.7383 - 709ms/epoch - 4ms/step\n","\n","Epoch 8/50                                           \n","\n","188/188 - 1s - loss: 0.8182 - categorical_accuracy: 0.6887 - val_loss: 0.6486 - val_categorical_accuracy: 0.7334 - 738ms/epoch - 4ms/step\n","\n","Epoch 9/50                                           \n","\n","188/188 - 1s - loss: 0.7987 - categorical_accuracy: 0.6983 - val_loss: 0.6370 - val_categorical_accuracy: 0.7377 - 694ms/epoch - 4ms/step\n","\n","Epoch 10/50                                          \n","\n","188/188 - 1s - loss: 0.7844 - categorical_accuracy: 0.7027 - val_loss: 0.5975 - val_categorical_accuracy: 0.7509 - 697ms/epoch - 4ms/step\n","\n","Epoch 11/50                                          \n","\n","188/188 - 1s - loss: 0.7708 - categorical_accuracy: 0.7060 - val_loss: 0.6258 - val_categorical_accuracy: 0.7347 - 705ms/epoch - 4ms/step\n","\n","Epoch 12/50                                          \n","\n","188/188 - 1s - loss: 0.7582 - categorical_accuracy: 0.7124 - val_loss: 0.5911 - val_categorical_accuracy: 0.7637 - 706ms/epoch - 4ms/step\n","\n","Epoch 13/50                                          \n","\n","188/188 - 1s - loss: 0.7622 - categorical_accuracy: 0.7190 - val_loss: 0.6254 - val_categorical_accuracy: 0.7368 - 756ms/epoch - 4ms/step\n","\n","Epoch 14/50                                          \n","\n","188/188 - 1s - loss: 0.7402 - categorical_accuracy: 0.7200 - val_loss: 0.5865 - val_categorical_accuracy: 0.7716 - 713ms/epoch - 4ms/step\n","\n","Epoch 15/50                                          \n","\n","188/188 - 1s - loss: 0.7380 - categorical_accuracy: 0.7251 - val_loss: 0.6079 - val_categorical_accuracy: 0.7734 - 737ms/epoch - 4ms/step\n","\n","Epoch 16/50                                          \n","\n","188/188 - 1s - loss: 0.7282 - categorical_accuracy: 0.7275 - val_loss: 0.5917 - val_categorical_accuracy: 0.7782 - 717ms/epoch - 4ms/step\n","\n","Epoch 17/50                                          \n","\n","188/188 - 1s - loss: 0.7251 - categorical_accuracy: 0.7266 - val_loss: 0.5659 - val_categorical_accuracy: 0.7838 - 707ms/epoch - 4ms/step\n","\n","Epoch 18/50                                          \n","\n","188/188 - 1s - loss: 0.7145 - categorical_accuracy: 0.7315 - val_loss: 0.5745 - val_categorical_accuracy: 0.7817 - 707ms/epoch - 4ms/step\n","\n","Epoch 19/50                                          \n","\n","188/188 - 1s - loss: 0.7051 - categorical_accuracy: 0.7341 - val_loss: 0.5765 - val_categorical_accuracy: 0.7798 - 776ms/epoch - 4ms/step\n","\n","Epoch 20/50                                          \n","\n","188/188 - 1s - loss: 0.7067 - categorical_accuracy: 0.7356 - val_loss: 0.5490 - val_categorical_accuracy: 0.7722 - 795ms/epoch - 4ms/step\n","\n","Epoch 21/50                                          \n","\n","188/188 - 1s - loss: 0.7113 - categorical_accuracy: 0.7337 - val_loss: 0.5646 - val_categorical_accuracy: 0.7833 - 772ms/epoch - 4ms/step\n","\n","Epoch 22/50                                          \n","\n","188/188 - 1s - loss: 0.7074 - categorical_accuracy: 0.7326 - val_loss: 0.5625 - val_categorical_accuracy: 0.7792 - 710ms/epoch - 4ms/step\n","\n","Epoch 23/50                                          \n","\n","188/188 - 1s - loss: 0.7015 - categorical_accuracy: 0.7378 - val_loss: 0.5650 - val_categorical_accuracy: 0.7858 - 696ms/epoch - 4ms/step\n","\n","Epoch 24/50                                          \n","\n","188/188 - 1s - loss: 0.6993 - categorical_accuracy: 0.7379 - val_loss: 0.5618 - val_categorical_accuracy: 0.7872 - 698ms/epoch - 4ms/step\n","\n","Epoch 25/50                                          \n","\n","188/188 - 1s - loss: 0.7050 - categorical_accuracy: 0.7405 - val_loss: 0.5637 - val_categorical_accuracy: 0.7774 - 741ms/epoch - 4ms/step\n","\n","Epoch 26/50                                          \n","\n","188/188 - 1s - loss: 0.6914 - categorical_accuracy: 0.7414 - val_loss: 0.5517 - val_categorical_accuracy: 0.7752 - 709ms/epoch - 4ms/step\n","\n","Epoch 27/50                                          \n","\n","188/188 - 1s - loss: 0.6939 - categorical_accuracy: 0.7398 - val_loss: 0.5458 - val_categorical_accuracy: 0.7840 - 711ms/epoch - 4ms/step\n","\n","Epoch 28/50                                          \n","\n","188/188 - 1s - loss: 0.6910 - categorical_accuracy: 0.7414 - val_loss: 0.5520 - val_categorical_accuracy: 0.7891 - 782ms/epoch - 4ms/step\n","\n","Epoch 29/50                                          \n","\n","188/188 - 1s - loss: 0.6918 - categorical_accuracy: 0.7399 - val_loss: 0.5580 - val_categorical_accuracy: 0.7784 - 776ms/epoch - 4ms/step\n","\n","Epoch 30/50                                          \n","\n","188/188 - 1s - loss: 0.6942 - categorical_accuracy: 0.7390 - val_loss: 0.5517 - val_categorical_accuracy: 0.7886 - 756ms/epoch - 4ms/step\n","\n","Epoch 31/50                                          \n","\n","188/188 - 1s - loss: 0.6865 - categorical_accuracy: 0.7429 - val_loss: 0.5479 - val_categorical_accuracy: 0.7778 - 716ms/epoch - 4ms/step\n","\n","Epoch 32/50                                          \n","\n","188/188 - 1s - loss: 0.6792 - categorical_accuracy: 0.7441 - val_loss: 0.5357 - val_categorical_accuracy: 0.7942 - 710ms/epoch - 4ms/step\n","\n","Epoch 33/50                                          \n","\n","188/188 - 1s - loss: 0.6837 - categorical_accuracy: 0.7426 - val_loss: 0.5476 - val_categorical_accuracy: 0.7846 - 724ms/epoch - 4ms/step\n","\n","Epoch 34/50                                          \n","\n","188/188 - 1s - loss: 0.6849 - categorical_accuracy: 0.7440 - val_loss: 0.5485 - val_categorical_accuracy: 0.7912 - 736ms/epoch - 4ms/step\n","\n","Epoch 35/50                                          \n","\n","188/188 - 1s - loss: 0.6843 - categorical_accuracy: 0.7425 - val_loss: 0.5558 - val_categorical_accuracy: 0.7895 - 703ms/epoch - 4ms/step\n","\n","Epoch 36/50                                          \n","\n","188/188 - 1s - loss: 0.6768 - categorical_accuracy: 0.7443 - val_loss: 0.5723 - val_categorical_accuracy: 0.7563 - 747ms/epoch - 4ms/step\n","\n","Epoch 37/50                                          \n","\n","188/188 - 1s - loss: 0.6777 - categorical_accuracy: 0.7460 - val_loss: 0.5600 - val_categorical_accuracy: 0.7856 - 717ms/epoch - 4ms/step\n","\n","Epoch 38/50                                          \n","\n","188/188 - 1s - loss: 0.6701 - categorical_accuracy: 0.7462 - val_loss: 0.5707 - val_categorical_accuracy: 0.7708 - 733ms/epoch - 4ms/step\n","\n","Epoch 39/50                                          \n","\n","188/188 - 1s - loss: 0.6672 - categorical_accuracy: 0.7446 - val_loss: 0.5451 - val_categorical_accuracy: 0.7933 - 717ms/epoch - 4ms/step\n","\n","Epoch 40/50                                          \n","\n","188/188 - 1s - loss: 0.6690 - categorical_accuracy: 0.7480 - val_loss: 0.5365 - val_categorical_accuracy: 0.7999 - 719ms/epoch - 4ms/step\n","\n","Epoch 41/50                                          \n","\n","188/188 - 1s - loss: 0.6771 - categorical_accuracy: 0.7451 - val_loss: 0.5940 - val_categorical_accuracy: 0.7731 - 727ms/epoch - 4ms/step\n","\n","Epoch 42/50                                          \n","\n","188/188 - 1s - loss: 0.6596 - categorical_accuracy: 0.7486 - val_loss: 0.5458 - val_categorical_accuracy: 0.7816 - 723ms/epoch - 4ms/step\n","\n","Epoch 43/50                                          \n","\n","188/188 - 1s - loss: 0.6786 - categorical_accuracy: 0.7441 - val_loss: 0.5567 - val_categorical_accuracy: 0.7893 - 743ms/epoch - 4ms/step\n","\n","Epoch 44/50                                          \n","\n","188/188 - 1s - loss: 0.6779 - categorical_accuracy: 0.7440 - val_loss: 0.5809 - val_categorical_accuracy: 0.7759 - 709ms/epoch - 4ms/step\n","\n","Epoch 45/50                                          \n","\n","188/188 - 1s - loss: 0.6734 - categorical_accuracy: 0.7465 - val_loss: 0.5902 - val_categorical_accuracy: 0.7469 - 701ms/epoch - 4ms/step\n","\n","Epoch 46/50                                          \n","\n","188/188 - 1s - loss: 0.6632 - categorical_accuracy: 0.7496 - val_loss: 0.5421 - val_categorical_accuracy: 0.7920 - 714ms/epoch - 4ms/step\n","\n","Epoch 47/50                                          \n","\n","188/188 - 1s - loss: 0.6568 - categorical_accuracy: 0.7503 - val_loss: 0.5769 - val_categorical_accuracy: 0.7929 - 775ms/epoch - 4ms/step\n","\n","Epoch 48/50                                          \n","\n","188/188 - 1s - loss: 0.6510 - categorical_accuracy: 0.7509 - val_loss: 0.5629 - val_categorical_accuracy: 0.7852 - 746ms/epoch - 4ms/step\n","\n","Epoch 49/50                                          \n","\n","188/188 - 1s - loss: 0.6664 - categorical_accuracy: 0.7485 - val_loss: 0.5570 - val_categorical_accuracy: 0.7906 - 730ms/epoch - 4ms/step\n","\n","Epoch 50/50                                          \n","\n","188/188 - 1s - loss: 0.6539 - categorical_accuracy: 0.7510 - val_loss: 0.5907 - val_categorical_accuracy: 0.7793 - 728ms/epoch - 4ms/step\n","\n","Best validation acc of epoch:                        \n","0.799916684627533                                    \n","Epoch 1/50                                                                     \n","\n","750/750 - 2s - loss: 1.9889 - categorical_accuracy: 0.2696 - val_loss: 1.2601 - val_categorical_accuracy: 0.6323 - 2s/epoch - 3ms/step\n","\n","Epoch 2/50                                                                     \n","\n","750/750 - 2s - loss: 1.4309 - categorical_accuracy: 0.4681 - val_loss: 0.8994 - val_categorical_accuracy: 0.7166 - 2s/epoch - 3ms/step\n","\n","Epoch 3/50                                                                     \n","\n","750/750 - 2s - loss: 1.2051 - categorical_accuracy: 0.5445 - val_loss: 0.7900 - val_categorical_accuracy: 0.7225 - 2s/epoch - 3ms/step\n","\n","Epoch 4/50                                                                     \n","\n","750/750 - 2s - loss: 1.0813 - categorical_accuracy: 0.5843 - val_loss: 0.7408 - val_categorical_accuracy: 0.7286 - 2s/epoch - 3ms/step\n","\n","Epoch 5/50                                                                     \n","\n","750/750 - 2s - loss: 1.0154 - categorical_accuracy: 0.6080 - val_loss: 0.7217 - val_categorical_accuracy: 0.7237 - 2s/epoch - 3ms/step\n","\n","Epoch 6/50                                                                     \n","\n","750/750 - 2s - loss: 0.9571 - categorical_accuracy: 0.6311 - val_loss: 0.6978 - val_categorical_accuracy: 0.7438 - 2s/epoch - 3ms/step\n","\n","Epoch 7/50                                                                     \n","\n","750/750 - 2s - loss: 0.9102 - categorical_accuracy: 0.6479 - val_loss: 0.6772 - val_categorical_accuracy: 0.7343 - 2s/epoch - 2ms/step\n","\n","Epoch 8/50                                                                     \n","\n","750/750 - 2s - loss: 0.8769 - categorical_accuracy: 0.6631 - val_loss: 0.6732 - val_categorical_accuracy: 0.7827 - 2s/epoch - 3ms/step\n","\n","Epoch 9/50                                                                     \n","\n","750/750 - 2s - loss: 0.8459 - categorical_accuracy: 0.6808 - val_loss: 0.6617 - val_categorical_accuracy: 0.7564 - 2s/epoch - 3ms/step\n","\n","Epoch 10/50                                                                    \n","\n","750/750 - 2s - loss: 0.8340 - categorical_accuracy: 0.6831 - val_loss: 0.6349 - val_categorical_accuracy: 0.7591 - 2s/epoch - 3ms/step\n","\n","Epoch 11/50                                                                    \n","\n","750/750 - 2s - loss: 0.8086 - categorical_accuracy: 0.6939 - val_loss: 0.6235 - val_categorical_accuracy: 0.8025 - 2s/epoch - 3ms/step\n","\n","Epoch 12/50                                                                    \n","\n","750/750 - 2s - loss: 0.7889 - categorical_accuracy: 0.7029 - val_loss: 0.6269 - val_categorical_accuracy: 0.7923 - 2s/epoch - 3ms/step\n","\n","Epoch 13/50                                                                    \n","\n","750/750 - 2s - loss: 0.7756 - categorical_accuracy: 0.7096 - val_loss: 0.6219 - val_categorical_accuracy: 0.7784 - 2s/epoch - 3ms/step\n","\n","Epoch 14/50                                                                    \n","\n","750/750 - 2s - loss: 0.7526 - categorical_accuracy: 0.7161 - val_loss: 0.6111 - val_categorical_accuracy: 0.7832 - 2s/epoch - 3ms/step\n","\n","Epoch 15/50                                                                    \n","\n","750/750 - 2s - loss: 0.7412 - categorical_accuracy: 0.7249 - val_loss: 0.5969 - val_categorical_accuracy: 0.8124 - 2s/epoch - 3ms/step\n","\n","Epoch 16/50                                                                    \n","\n","750/750 - 2s - loss: 0.7327 - categorical_accuracy: 0.7301 - val_loss: 0.5937 - val_categorical_accuracy: 0.7878 - 2s/epoch - 3ms/step\n","\n","Epoch 17/50                                                                    \n","\n","750/750 - 2s - loss: 0.7190 - categorical_accuracy: 0.7345 - val_loss: 0.5910 - val_categorical_accuracy: 0.7994 - 2s/epoch - 3ms/step\n","\n","Epoch 18/50                                                                    \n","\n","750/750 - 2s - loss: 0.7087 - categorical_accuracy: 0.7422 - val_loss: 0.5670 - val_categorical_accuracy: 0.8129 - 2s/epoch - 3ms/step\n","\n","Epoch 19/50                                                                    \n","\n","750/750 - 2s - loss: 0.6912 - categorical_accuracy: 0.7468 - val_loss: 0.5681 - val_categorical_accuracy: 0.8043 - 2s/epoch - 3ms/step\n","\n","Epoch 20/50                                                                    \n","\n","750/750 - 2s - loss: 0.6912 - categorical_accuracy: 0.7505 - val_loss: 0.5627 - val_categorical_accuracy: 0.8099 - 2s/epoch - 3ms/step\n","\n","Epoch 21/50                                                                    \n","\n","750/750 - 2s - loss: 0.6808 - categorical_accuracy: 0.7526 - val_loss: 0.5726 - val_categorical_accuracy: 0.8155 - 2s/epoch - 3ms/step\n","\n","Epoch 22/50                                                                    \n","\n","750/750 - 2s - loss: 0.6730 - categorical_accuracy: 0.7549 - val_loss: 0.5775 - val_categorical_accuracy: 0.7911 - 2s/epoch - 3ms/step\n","\n","Epoch 23/50                                                                    \n","\n","750/750 - 2s - loss: 0.6614 - categorical_accuracy: 0.7580 - val_loss: 0.5755 - val_categorical_accuracy: 0.8046 - 2s/epoch - 3ms/step\n","\n","Epoch 24/50                                                                    \n","\n","750/750 - 2s - loss: 0.6538 - categorical_accuracy: 0.7653 - val_loss: 0.5589 - val_categorical_accuracy: 0.8044 - 2s/epoch - 3ms/step\n","\n","Epoch 25/50                                                                    \n","\n","750/750 - 2s - loss: 0.6447 - categorical_accuracy: 0.7685 - val_loss: 0.5656 - val_categorical_accuracy: 0.7919 - 2s/epoch - 3ms/step\n","\n","Epoch 26/50                                                                    \n","\n","750/750 - 2s - loss: 0.6414 - categorical_accuracy: 0.7705 - val_loss: 0.5378 - val_categorical_accuracy: 0.8084 - 2s/epoch - 3ms/step\n","\n","Epoch 27/50                                                                    \n","\n","750/750 - 2s - loss: 0.6396 - categorical_accuracy: 0.7746 - val_loss: 0.5615 - val_categorical_accuracy: 0.7989 - 2s/epoch - 3ms/step\n","\n","Epoch 28/50                                                                    \n","\n","750/750 - 2s - loss: 0.6286 - categorical_accuracy: 0.7767 - val_loss: 0.5362 - val_categorical_accuracy: 0.8198 - 2s/epoch - 3ms/step\n","\n","Epoch 29/50                                                                    \n","\n","750/750 - 2s - loss: 0.6266 - categorical_accuracy: 0.7765 - val_loss: 0.5428 - val_categorical_accuracy: 0.8082 - 2s/epoch - 3ms/step\n","\n","Epoch 30/50                                                                    \n","\n","750/750 - 2s - loss: 0.6159 - categorical_accuracy: 0.7828 - val_loss: 0.5383 - val_categorical_accuracy: 0.8161 - 2s/epoch - 3ms/step\n","\n","Epoch 31/50                                                                    \n","\n","750/750 - 2s - loss: 0.6134 - categorical_accuracy: 0.7822 - val_loss: 0.5171 - val_categorical_accuracy: 0.8193 - 2s/epoch - 3ms/step\n","\n","Epoch 32/50                                                                    \n","\n","750/750 - 2s - loss: 0.6117 - categorical_accuracy: 0.7829 - val_loss: 0.5436 - val_categorical_accuracy: 0.8032 - 2s/epoch - 3ms/step\n","\n","Epoch 33/50                                                                    \n","\n","750/750 - 2s - loss: 0.6025 - categorical_accuracy: 0.7871 - val_loss: 0.5306 - val_categorical_accuracy: 0.8165 - 2s/epoch - 3ms/step\n","\n","Epoch 34/50                                                                    \n","\n","750/750 - 2s - loss: 0.6001 - categorical_accuracy: 0.7874 - val_loss: 0.5266 - val_categorical_accuracy: 0.8146 - 2s/epoch - 3ms/step\n","\n","Epoch 35/50                                                                    \n","\n","750/750 - 2s - loss: 0.5887 - categorical_accuracy: 0.7908 - val_loss: 0.5113 - val_categorical_accuracy: 0.8215 - 2s/epoch - 3ms/step\n","\n","Epoch 36/50                                                                    \n","\n","750/750 - 2s - loss: 0.5917 - categorical_accuracy: 0.7910 - val_loss: 0.5208 - val_categorical_accuracy: 0.8141 - 2s/epoch - 3ms/step\n","\n","Epoch 37/50                                                                    \n","\n","750/750 - 2s - loss: 0.5793 - categorical_accuracy: 0.7969 - val_loss: 0.5133 - val_categorical_accuracy: 0.8133 - 2s/epoch - 3ms/step\n","\n","Epoch 38/50                                                                    \n","\n","750/750 - 2s - loss: 0.5768 - categorical_accuracy: 0.7950 - val_loss: 0.5036 - val_categorical_accuracy: 0.8207 - 2s/epoch - 3ms/step\n","\n","Epoch 39/50                                                                    \n","\n","750/750 - 2s - loss: 0.5740 - categorical_accuracy: 0.7990 - val_loss: 0.5207 - val_categorical_accuracy: 0.8142 - 2s/epoch - 3ms/step\n","\n","Epoch 40/50                                                                    \n","\n","750/750 - 2s - loss: 0.5644 - categorical_accuracy: 0.8012 - val_loss: 0.5198 - val_categorical_accuracy: 0.8034 - 2s/epoch - 3ms/step\n","\n","Epoch 41/50                                                                    \n","\n","750/750 - 2s - loss: 0.5632 - categorical_accuracy: 0.8039 - val_loss: 0.5234 - val_categorical_accuracy: 0.8082 - 2s/epoch - 3ms/step\n","\n","Epoch 42/50                                                                    \n","\n","750/750 - 2s - loss: 0.5622 - categorical_accuracy: 0.8035 - val_loss: 0.5109 - val_categorical_accuracy: 0.8062 - 2s/epoch - 3ms/step\n","\n","Epoch 43/50                                                                    \n","\n","750/750 - 2s - loss: 0.5551 - categorical_accuracy: 0.8059 - val_loss: 0.5030 - val_categorical_accuracy: 0.8276 - 2s/epoch - 3ms/step\n","\n","Epoch 44/50                                                                    \n","\n","750/750 - 2s - loss: 0.5508 - categorical_accuracy: 0.8078 - val_loss: 0.4930 - val_categorical_accuracy: 0.8287 - 2s/epoch - 3ms/step\n","\n","Epoch 45/50                                                                    \n","\n","750/750 - 2s - loss: 0.5469 - categorical_accuracy: 0.8092 - val_loss: 0.4779 - val_categorical_accuracy: 0.8373 - 2s/epoch - 3ms/step\n","\n","Epoch 46/50                                                                    \n","\n","750/750 - 2s - loss: 0.5447 - categorical_accuracy: 0.8115 - val_loss: 0.4871 - val_categorical_accuracy: 0.8300 - 2s/epoch - 3ms/step\n","\n","Epoch 47/50                                                                    \n","\n","750/750 - 2s - loss: 0.5405 - categorical_accuracy: 0.8099 - val_loss: 0.5095 - val_categorical_accuracy: 0.8240 - 2s/epoch - 3ms/step\n","\n","Epoch 48/50                                                                    \n","\n","750/750 - 2s - loss: 0.5373 - categorical_accuracy: 0.8112 - val_loss: 0.4954 - val_categorical_accuracy: 0.8171 - 2s/epoch - 3ms/step\n","\n","Epoch 49/50                                                                    \n","\n","750/750 - 2s - loss: 0.5375 - categorical_accuracy: 0.8124 - val_loss: 0.4884 - val_categorical_accuracy: 0.8355 - 2s/epoch - 3ms/step\n","\n","Epoch 50/50                                                                    \n","\n","750/750 - 2s - loss: 0.5327 - categorical_accuracy: 0.8161 - val_loss: 0.4803 - val_categorical_accuracy: 0.8378 - 2s/epoch - 3ms/step\n","\n","Best validation acc of epoch:                                                  \n","0.8378333449363708                                                             \n","Epoch 1/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.6968 - categorical_accuracy: 0.7548 - val_loss: 0.4772 - val_categorical_accuracy: 0.8333 - 6s/epoch - 4ms/step\n","\n","Epoch 2/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.5225 - categorical_accuracy: 0.8247 - val_loss: 0.4533 - val_categorical_accuracy: 0.8498 - 6s/epoch - 4ms/step\n","\n","Epoch 3/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.5051 - categorical_accuracy: 0.8388 - val_loss: 0.4340 - val_categorical_accuracy: 0.8585 - 6s/epoch - 4ms/step\n","\n","Epoch 4/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.4988 - categorical_accuracy: 0.8418 - val_loss: 0.4205 - val_categorical_accuracy: 0.8648 - 6s/epoch - 4ms/step\n","\n","Epoch 5/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.4975 - categorical_accuracy: 0.8459 - val_loss: 0.4714 - val_categorical_accuracy: 0.8402 - 6s/epoch - 4ms/step\n","\n","Epoch 6/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.5105 - categorical_accuracy: 0.8449 - val_loss: 0.4453 - val_categorical_accuracy: 0.8548 - 6s/epoch - 4ms/step\n","\n","Epoch 7/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.5199 - categorical_accuracy: 0.8453 - val_loss: 0.4729 - val_categorical_accuracy: 0.8530 - 6s/epoch - 4ms/step\n","\n","Epoch 8/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.5264 - categorical_accuracy: 0.8464 - val_loss: 0.4679 - val_categorical_accuracy: 0.8428 - 6s/epoch - 4ms/step\n","\n","Epoch 9/50                                                                      \n","\n","1500/1500 - 6s - loss: 0.5222 - categorical_accuracy: 0.8463 - val_loss: 0.4693 - val_categorical_accuracy: 0.8560 - 6s/epoch - 4ms/step\n","\n","Epoch 10/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.5289 - categorical_accuracy: 0.8475 - val_loss: 0.4790 - val_categorical_accuracy: 0.8385 - 6s/epoch - 4ms/step\n","\n","Epoch 11/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.5279 - categorical_accuracy: 0.8464 - val_loss: 0.4625 - val_categorical_accuracy: 0.8572 - 6s/epoch - 4ms/step\n","\n","Epoch 12/50                                                                     \n","\n","1500/1500 - 8s - loss: 0.5424 - categorical_accuracy: 0.8458 - val_loss: 0.4913 - val_categorical_accuracy: 0.8549 - 8s/epoch - 5ms/step\n","\n","Epoch 13/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.5466 - categorical_accuracy: 0.8474 - val_loss: 0.4866 - val_categorical_accuracy: 0.8622 - 6s/epoch - 4ms/step\n","\n","Epoch 14/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.5491 - categorical_accuracy: 0.8511 - val_loss: 0.5502 - val_categorical_accuracy: 0.8408 - 6s/epoch - 4ms/step\n","\n","Epoch 15/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5447 - categorical_accuracy: 0.8492 - val_loss: 0.5331 - val_categorical_accuracy: 0.8491 - 7s/epoch - 5ms/step\n","\n","Epoch 16/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5451 - categorical_accuracy: 0.8483 - val_loss: 0.5895 - val_categorical_accuracy: 0.8427 - 7s/epoch - 5ms/step\n","\n","Epoch 17/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5563 - categorical_accuracy: 0.8498 - val_loss: 0.5458 - val_categorical_accuracy: 0.8321 - 7s/epoch - 5ms/step\n","\n","Epoch 18/50                                                                     \n","\n","1500/1500 - 8s - loss: 0.5568 - categorical_accuracy: 0.8493 - val_loss: 0.5517 - val_categorical_accuracy: 0.8092 - 8s/epoch - 5ms/step\n","\n","Epoch 19/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5716 - categorical_accuracy: 0.8485 - val_loss: 0.6448 - val_categorical_accuracy: 0.8048 - 7s/epoch - 4ms/step\n","\n","Epoch 20/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5659 - categorical_accuracy: 0.8500 - val_loss: 0.5820 - val_categorical_accuracy: 0.8482 - 7s/epoch - 4ms/step\n","\n","Epoch 21/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5532 - categorical_accuracy: 0.8513 - val_loss: 0.6411 - val_categorical_accuracy: 0.8058 - 7s/epoch - 4ms/step\n","\n","Epoch 22/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5844 - categorical_accuracy: 0.8522 - val_loss: 0.5730 - val_categorical_accuracy: 0.8537 - 7s/epoch - 4ms/step\n","\n","Epoch 23/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5890 - categorical_accuracy: 0.8474 - val_loss: 0.6165 - val_categorical_accuracy: 0.8261 - 7s/epoch - 4ms/step\n","\n","Epoch 24/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5590 - categorical_accuracy: 0.8533 - val_loss: 0.5897 - val_categorical_accuracy: 0.8468 - 7s/epoch - 5ms/step\n","\n","Epoch 25/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5798 - categorical_accuracy: 0.8502 - val_loss: 0.6008 - val_categorical_accuracy: 0.8178 - 7s/epoch - 5ms/step\n","\n","Epoch 26/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5776 - categorical_accuracy: 0.8509 - val_loss: 0.6955 - val_categorical_accuracy: 0.8102 - 7s/epoch - 4ms/step\n","\n","Epoch 27/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.5966 - categorical_accuracy: 0.8478 - val_loss: 0.6436 - val_categorical_accuracy: 0.8395 - 6s/epoch - 4ms/step\n","\n","Epoch 28/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.5962 - categorical_accuracy: 0.8492 - val_loss: 0.6147 - val_categorical_accuracy: 0.8511 - 6s/epoch - 4ms/step\n","\n","Epoch 29/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6111 - categorical_accuracy: 0.8488 - val_loss: 0.6906 - val_categorical_accuracy: 0.8272 - 6s/epoch - 4ms/step\n","\n","Epoch 30/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6041 - categorical_accuracy: 0.8471 - val_loss: 0.6823 - val_categorical_accuracy: 0.8393 - 6s/epoch - 4ms/step\n","\n","Epoch 31/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.5945 - categorical_accuracy: 0.8471 - val_loss: 0.6983 - val_categorical_accuracy: 0.8185 - 7s/epoch - 5ms/step\n","\n","Epoch 32/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6199 - categorical_accuracy: 0.8473 - val_loss: 0.7280 - val_categorical_accuracy: 0.8152 - 6s/epoch - 4ms/step\n","\n","Epoch 33/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6108 - categorical_accuracy: 0.8435 - val_loss: 0.7927 - val_categorical_accuracy: 0.8492 - 6s/epoch - 4ms/step\n","\n","Epoch 34/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6185 - categorical_accuracy: 0.8470 - val_loss: 0.6804 - val_categorical_accuracy: 0.8516 - 6s/epoch - 4ms/step\n","\n","Epoch 35/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.6204 - categorical_accuracy: 0.8460 - val_loss: 0.7016 - val_categorical_accuracy: 0.8186 - 7s/epoch - 5ms/step\n","\n","Epoch 36/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6259 - categorical_accuracy: 0.8456 - val_loss: 0.7303 - val_categorical_accuracy: 0.8399 - 6s/epoch - 4ms/step\n","\n","Epoch 37/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6351 - categorical_accuracy: 0.8417 - val_loss: 0.7446 - val_categorical_accuracy: 0.8005 - 6s/epoch - 4ms/step\n","\n","Epoch 38/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6314 - categorical_accuracy: 0.8417 - val_loss: 0.7607 - val_categorical_accuracy: 0.8323 - 6s/epoch - 4ms/step\n","\n","Epoch 39/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6524 - categorical_accuracy: 0.8426 - val_loss: 0.7951 - val_categorical_accuracy: 0.8143 - 6s/epoch - 4ms/step\n","\n","Epoch 40/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.6596 - categorical_accuracy: 0.8401 - val_loss: 0.7709 - val_categorical_accuracy: 0.8246 - 7s/epoch - 4ms/step\n","\n","Epoch 41/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.6621 - categorical_accuracy: 0.8407 - val_loss: 0.7907 - val_categorical_accuracy: 0.8455 - 7s/epoch - 5ms/step\n","\n","Epoch 42/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.6404 - categorical_accuracy: 0.8424 - val_loss: 0.7870 - val_categorical_accuracy: 0.8265 - 7s/epoch - 4ms/step\n","\n","Epoch 43/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6574 - categorical_accuracy: 0.8391 - val_loss: 0.7767 - val_categorical_accuracy: 0.8400 - 6s/epoch - 4ms/step\n","\n","Epoch 44/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6862 - categorical_accuracy: 0.8370 - val_loss: 0.7990 - val_categorical_accuracy: 0.8067 - 6s/epoch - 4ms/step\n","\n","Epoch 45/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.6675 - categorical_accuracy: 0.8363 - val_loss: 0.8638 - val_categorical_accuracy: 0.8378 - 6s/epoch - 4ms/step\n","\n","Epoch 46/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.6683 - categorical_accuracy: 0.8411 - val_loss: 0.8601 - val_categorical_accuracy: 0.8586 - 7s/epoch - 5ms/step\n","\n","Epoch 47/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.6777 - categorical_accuracy: 0.8375 - val_loss: 0.7650 - val_categorical_accuracy: 0.8490 - 7s/epoch - 5ms/step\n","\n","Epoch 48/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.7001 - categorical_accuracy: 0.8372 - val_loss: 0.8455 - val_categorical_accuracy: 0.8448 - 7s/epoch - 4ms/step\n","\n","Epoch 49/50                                                                     \n","\n","1500/1500 - 7s - loss: 0.6722 - categorical_accuracy: 0.8381 - val_loss: 0.7506 - val_categorical_accuracy: 0.8375 - 7s/epoch - 4ms/step\n","\n","Epoch 50/50                                                                     \n","\n","1500/1500 - 6s - loss: 0.7010 - categorical_accuracy: 0.8378 - val_loss: 1.0375 - val_categorical_accuracy: 0.8396 - 6s/epoch - 4ms/step\n","\n","Best validation acc of epoch:                                                   \n","0.8647500276565552                                                              \n","Epoch 1/50                                                                       \n","\n","750/750 - 3s - loss: 1.0856 - categorical_accuracy: 0.5821 - val_loss: 0.5869 - val_categorical_accuracy: 0.7757 - 3s/epoch - 4ms/step\n","\n","Epoch 2/50                                                                       \n","\n","750/750 - 3s - loss: 0.7381 - categorical_accuracy: 0.7246 - val_loss: 0.5516 - val_categorical_accuracy: 0.8177 - 3s/epoch - 3ms/step\n","\n","Epoch 3/50                                                                       \n","\n","750/750 - 2s - loss: 0.6635 - categorical_accuracy: 0.7581 - val_loss: 0.5292 - val_categorical_accuracy: 0.8078 - 2s/epoch - 3ms/step\n","\n","Epoch 4/50                                                                       \n","\n","750/750 - 3s - loss: 0.6205 - categorical_accuracy: 0.7764 - val_loss: 0.5082 - val_categorical_accuracy: 0.8257 - 3s/epoch - 4ms/step\n","\n","Epoch 5/50                                                                       \n","\n","750/750 - 3s - loss: 0.5973 - categorical_accuracy: 0.7845 - val_loss: 0.5031 - val_categorical_accuracy: 0.8135 - 3s/epoch - 4ms/step\n","\n","Epoch 6/50                                                                       \n","\n","750/750 - 4s - loss: 0.5781 - categorical_accuracy: 0.7940 - val_loss: 0.5104 - val_categorical_accuracy: 0.8407 - 4s/epoch - 5ms/step\n","\n","Epoch 7/50                                                                       \n","\n","750/750 - 3s - loss: 0.5680 - categorical_accuracy: 0.8001 - val_loss: 0.4869 - val_categorical_accuracy: 0.8424 - 3s/epoch - 4ms/step\n","\n","Epoch 8/50                                                                       \n","\n","750/750 - 3s - loss: 0.5550 - categorical_accuracy: 0.8043 - val_loss: 0.5139 - val_categorical_accuracy: 0.8416 - 3s/epoch - 4ms/step\n","\n","Epoch 9/50                                                                       \n","\n","750/750 - 3s - loss: 0.5445 - categorical_accuracy: 0.8068 - val_loss: 0.4948 - val_categorical_accuracy: 0.8424 - 3s/epoch - 4ms/step\n","\n","Epoch 10/50                                                                      \n","\n","750/750 - 3s - loss: 0.5409 - categorical_accuracy: 0.8089 - val_loss: 0.4866 - val_categorical_accuracy: 0.8459 - 3s/epoch - 4ms/step\n","\n","Epoch 11/50                                                                      \n","\n","750/750 - 4s - loss: 0.5353 - categorical_accuracy: 0.8097 - val_loss: 0.4824 - val_categorical_accuracy: 0.8459 - 4s/epoch - 5ms/step\n","\n","Epoch 12/50                                                                      \n","\n","750/750 - 3s - loss: 0.5201 - categorical_accuracy: 0.8141 - val_loss: 0.4623 - val_categorical_accuracy: 0.8504 - 3s/epoch - 4ms/step\n","\n","Epoch 13/50                                                                      \n","\n","750/750 - 4s - loss: 0.5233 - categorical_accuracy: 0.8160 - val_loss: 0.4597 - val_categorical_accuracy: 0.8534 - 4s/epoch - 5ms/step\n","\n","Epoch 14/50                                                                      \n","\n","750/750 - 3s - loss: 0.5194 - categorical_accuracy: 0.8167 - val_loss: 0.4821 - val_categorical_accuracy: 0.8541 - 3s/epoch - 5ms/step\n","\n","Epoch 15/50                                                                      \n","\n","750/750 - 3s - loss: 0.5172 - categorical_accuracy: 0.8169 - val_loss: 0.4640 - val_categorical_accuracy: 0.8528 - 3s/epoch - 5ms/step\n","\n","Epoch 16/50                                                                      \n","\n","750/750 - 3s - loss: 0.5086 - categorical_accuracy: 0.8184 - val_loss: 0.4426 - val_categorical_accuracy: 0.8579 - 3s/epoch - 4ms/step\n","\n","Epoch 17/50                                                                      \n","\n","750/750 - 3s - loss: 0.5066 - categorical_accuracy: 0.8212 - val_loss: 0.4548 - val_categorical_accuracy: 0.8550 - 3s/epoch - 4ms/step\n","\n","Epoch 18/50                                                                      \n","\n","750/750 - 3s - loss: 0.5017 - categorical_accuracy: 0.8228 - val_loss: 0.4431 - val_categorical_accuracy: 0.8606 - 3s/epoch - 4ms/step\n","\n","Epoch 19/50                                                                      \n","\n","750/750 - 3s - loss: 0.4969 - categorical_accuracy: 0.8239 - val_loss: 0.4656 - val_categorical_accuracy: 0.8579 - 3s/epoch - 4ms/step\n","\n","Epoch 20/50                                                                      \n","\n","750/750 - 4s - loss: 0.4962 - categorical_accuracy: 0.8245 - val_loss: 0.4490 - val_categorical_accuracy: 0.8599 - 4s/epoch - 5ms/step\n","\n","Epoch 21/50                                                                      \n","\n","750/750 - 3s - loss: 0.4993 - categorical_accuracy: 0.8242 - val_loss: 0.4406 - val_categorical_accuracy: 0.8628 - 3s/epoch - 5ms/step\n","\n","Epoch 22/50                                                                      \n","\n","750/750 - 3s - loss: 0.4918 - categorical_accuracy: 0.8285 - val_loss: 0.4692 - val_categorical_accuracy: 0.8603 - 3s/epoch - 4ms/step\n","\n","Epoch 23/50                                                                      \n","\n","750/750 - 3s - loss: 0.4896 - categorical_accuracy: 0.8270 - val_loss: 0.4311 - val_categorical_accuracy: 0.8615 - 3s/epoch - 4ms/step\n","\n","Epoch 24/50                                                                      \n","\n","750/750 - 4s - loss: 0.4867 - categorical_accuracy: 0.8287 - val_loss: 0.4297 - val_categorical_accuracy: 0.8627 - 4s/epoch - 6ms/step\n","\n","Epoch 25/50                                                                      \n","\n","750/750 - 3s - loss: 0.4810 - categorical_accuracy: 0.8323 - val_loss: 0.4292 - val_categorical_accuracy: 0.8585 - 3s/epoch - 5ms/step\n","\n","Epoch 26/50                                                                      \n","\n","750/750 - 3s - loss: 0.4812 - categorical_accuracy: 0.8320 - val_loss: 0.4402 - val_categorical_accuracy: 0.8577 - 3s/epoch - 4ms/step\n","\n","Epoch 27/50                                                                      \n","\n","750/750 - 3s - loss: 0.4808 - categorical_accuracy: 0.8317 - val_loss: 0.4322 - val_categorical_accuracy: 0.8611 - 3s/epoch - 4ms/step\n","\n","Epoch 28/50                                                                      \n","\n","750/750 - 3s - loss: 0.4734 - categorical_accuracy: 0.8354 - val_loss: 0.4185 - val_categorical_accuracy: 0.8594 - 3s/epoch - 4ms/step\n","\n","Epoch 29/50                                                                      \n","\n","750/750 - 3s - loss: 0.4802 - categorical_accuracy: 0.8300 - val_loss: 0.4379 - val_categorical_accuracy: 0.8643 - 3s/epoch - 4ms/step\n","\n","Epoch 30/50                                                                      \n","\n","750/750 - 3s - loss: 0.4681 - categorical_accuracy: 0.8361 - val_loss: 0.4340 - val_categorical_accuracy: 0.8607 - 3s/epoch - 4ms/step\n","\n","Epoch 31/50                                                                      \n","\n","750/750 - 3s - loss: 0.4740 - categorical_accuracy: 0.8339 - val_loss: 0.4159 - val_categorical_accuracy: 0.8660 - 3s/epoch - 4ms/step\n","\n","Epoch 32/50                                                                      \n","\n","750/750 - 3s - loss: 0.4680 - categorical_accuracy: 0.8347 - val_loss: 0.4168 - val_categorical_accuracy: 0.8656 - 3s/epoch - 4ms/step\n","\n","Epoch 33/50                                                                      \n","\n","750/750 - 3s - loss: 0.4624 - categorical_accuracy: 0.8354 - val_loss: 0.3995 - val_categorical_accuracy: 0.8638 - 3s/epoch - 4ms/step\n","\n","Epoch 34/50                                                                      \n","\n","750/750 - 3s - loss: 0.4668 - categorical_accuracy: 0.8368 - val_loss: 0.4107 - val_categorical_accuracy: 0.8637 - 3s/epoch - 4ms/step\n","\n","Epoch 35/50                                                                      \n","\n","750/750 - 3s - loss: 0.4741 - categorical_accuracy: 0.8355 - val_loss: 0.4103 - val_categorical_accuracy: 0.8627 - 3s/epoch - 4ms/step\n","\n","Epoch 36/50                                                                      \n","\n","750/750 - 3s - loss: 0.4695 - categorical_accuracy: 0.8365 - val_loss: 0.4099 - val_categorical_accuracy: 0.8645 - 3s/epoch - 4ms/step\n","\n","Epoch 37/50                                                                      \n","\n","750/750 - 3s - loss: 0.4715 - categorical_accuracy: 0.8339 - val_loss: 0.4119 - val_categorical_accuracy: 0.8676 - 3s/epoch - 4ms/step\n","\n","Epoch 38/50                                                                      \n","\n","750/750 - 4s - loss: 0.4614 - categorical_accuracy: 0.8354 - val_loss: 0.4199 - val_categorical_accuracy: 0.8654 - 4s/epoch - 6ms/step\n","\n","Epoch 39/50                                                                      \n","\n","750/750 - 3s - loss: 0.4611 - categorical_accuracy: 0.8370 - val_loss: 0.4341 - val_categorical_accuracy: 0.8644 - 3s/epoch - 5ms/step\n","\n","Epoch 40/50                                                                      \n","\n","750/750 - 3s - loss: 0.4615 - categorical_accuracy: 0.8386 - val_loss: 0.4221 - val_categorical_accuracy: 0.8685 - 3s/epoch - 4ms/step\n","\n","Epoch 41/50                                                                      \n","\n","750/750 - 3s - loss: 0.4600 - categorical_accuracy: 0.8388 - val_loss: 0.4069 - val_categorical_accuracy: 0.8647 - 3s/epoch - 3ms/step\n","\n","Epoch 42/50                                                                      \n","\n","750/750 - 3s - loss: 0.4591 - categorical_accuracy: 0.8384 - val_loss: 0.4103 - val_categorical_accuracy: 0.8663 - 3s/epoch - 3ms/step\n","\n","Epoch 43/50                                                                      \n","\n","750/750 - 3s - loss: 0.4595 - categorical_accuracy: 0.8386 - val_loss: 0.4335 - val_categorical_accuracy: 0.8662 - 3s/epoch - 4ms/step\n","\n","Epoch 44/50                                                                      \n","\n","750/750 - 3s - loss: 0.4617 - categorical_accuracy: 0.8368 - val_loss: 0.4086 - val_categorical_accuracy: 0.8646 - 3s/epoch - 4ms/step\n","\n","Epoch 45/50                                                                      \n","\n","750/750 - 4s - loss: 0.4529 - categorical_accuracy: 0.8425 - val_loss: 0.3973 - val_categorical_accuracy: 0.8701 - 4s/epoch - 5ms/step\n","\n","Epoch 46/50                                                                      \n","\n","750/750 - 3s - loss: 0.4590 - categorical_accuracy: 0.8412 - val_loss: 0.4035 - val_categorical_accuracy: 0.8702 - 3s/epoch - 4ms/step\n","\n","Epoch 47/50                                                                      \n","\n","750/750 - 4s - loss: 0.4521 - categorical_accuracy: 0.8414 - val_loss: 0.4165 - val_categorical_accuracy: 0.8642 - 4s/epoch - 5ms/step\n","\n","Epoch 48/50                                                                      \n","\n","750/750 - 3s - loss: 0.4515 - categorical_accuracy: 0.8407 - val_loss: 0.4012 - val_categorical_accuracy: 0.8651 - 3s/epoch - 5ms/step\n","\n","Epoch 49/50                                                                      \n","\n","750/750 - 4s - loss: 0.4525 - categorical_accuracy: 0.8426 - val_loss: 0.4025 - val_categorical_accuracy: 0.8668 - 4s/epoch - 5ms/step\n","\n","Epoch 50/50                                                                      \n","\n","750/750 - 6s - loss: 0.4491 - categorical_accuracy: 0.8428 - val_loss: 0.4178 - val_categorical_accuracy: 0.8685 - 6s/epoch - 8ms/step\n","\n","Best validation acc of epoch:                                                    \n","0.8701666593551636                                                               \n","Epoch 1/50                                                                       \n","\n","375/375 - 4s - loss: 0.7490 - categorical_accuracy: 0.7254 - val_loss: 0.4582 - val_categorical_accuracy: 0.8354 - 4s/epoch - 11ms/step\n","\n","Epoch 2/50                                                                       \n","\n","375/375 - 2s - loss: 0.5015 - categorical_accuracy: 0.8218 - val_loss: 0.4128 - val_categorical_accuracy: 0.8473 - 2s/epoch - 6ms/step\n","\n","Epoch 3/50                                                                       \n","\n","375/375 - 3s - loss: 0.4558 - categorical_accuracy: 0.8379 - val_loss: 0.3948 - val_categorical_accuracy: 0.8542 - 3s/epoch - 9ms/step\n","\n","Epoch 4/50                                                                       \n","\n","375/375 - 3s - loss: 0.4251 - categorical_accuracy: 0.8471 - val_loss: 0.4002 - val_categorical_accuracy: 0.8536 - 3s/epoch - 9ms/step\n","\n","Epoch 5/50                                                                       \n","\n","375/375 - 2s - loss: 0.4086 - categorical_accuracy: 0.8542 - val_loss: 0.3739 - val_categorical_accuracy: 0.8609 - 2s/epoch - 5ms/step\n","\n","Epoch 6/50                                                                       \n","\n","375/375 - 2s - loss: 0.3962 - categorical_accuracy: 0.8591 - val_loss: 0.3531 - val_categorical_accuracy: 0.8742 - 2s/epoch - 5ms/step\n","\n","Epoch 7/50                                                                       \n","\n","375/375 - 2s - loss: 0.3838 - categorical_accuracy: 0.8639 - val_loss: 0.3720 - val_categorical_accuracy: 0.8648 - 2s/epoch - 4ms/step\n","\n","Epoch 8/50                                                                       \n","\n","375/375 - 2s - loss: 0.3725 - categorical_accuracy: 0.8677 - val_loss: 0.3520 - val_categorical_accuracy: 0.8744 - 2s/epoch - 5ms/step\n","\n","Epoch 9/50                                                                       \n","\n","375/375 - 2s - loss: 0.3679 - categorical_accuracy: 0.8691 - val_loss: 0.3453 - val_categorical_accuracy: 0.8758 - 2s/epoch - 5ms/step\n","\n","Epoch 10/50                                                                      \n","\n","375/375 - 2s - loss: 0.3543 - categorical_accuracy: 0.8731 - val_loss: 0.3413 - val_categorical_accuracy: 0.8839 - 2s/epoch - 5ms/step\n","\n","Epoch 11/50                                                                      \n","\n","375/375 - 2s - loss: 0.3532 - categorical_accuracy: 0.8745 - val_loss: 0.3366 - val_categorical_accuracy: 0.8792 - 2s/epoch - 5ms/step\n","\n","Epoch 12/50                                                                      \n","\n","375/375 - 2s - loss: 0.3480 - categorical_accuracy: 0.8763 - val_loss: 0.3429 - val_categorical_accuracy: 0.8824 - 2s/epoch - 6ms/step\n","\n","Epoch 13/50                                                                      \n","\n","375/375 - 2s - loss: 0.3427 - categorical_accuracy: 0.8775 - val_loss: 0.3474 - val_categorical_accuracy: 0.8791 - 2s/epoch - 6ms/step\n","\n","Epoch 14/50                                                                      \n","\n","375/375 - 2s - loss: 0.3399 - categorical_accuracy: 0.8784 - val_loss: 0.3318 - val_categorical_accuracy: 0.8852 - 2s/epoch - 5ms/step\n","\n","Epoch 15/50                                                                      \n","\n","375/375 - 2s - loss: 0.3348 - categorical_accuracy: 0.8806 - val_loss: 0.3333 - val_categorical_accuracy: 0.8856 - 2s/epoch - 5ms/step\n","\n","Epoch 16/50                                                                      \n","\n","375/375 - 2s - loss: 0.3287 - categorical_accuracy: 0.8816 - val_loss: 0.3432 - val_categorical_accuracy: 0.8796 - 2s/epoch - 5ms/step\n","\n","Epoch 17/50                                                                      \n","\n","375/375 - 2s - loss: 0.3297 - categorical_accuracy: 0.8807 - val_loss: 0.3427 - val_categorical_accuracy: 0.8809 - 2s/epoch - 4ms/step\n","\n","Epoch 18/50                                                                      \n","\n","375/375 - 2s - loss: 0.3218 - categorical_accuracy: 0.8858 - val_loss: 0.3261 - val_categorical_accuracy: 0.8885 - 2s/epoch - 5ms/step\n","\n","Epoch 19/50                                                                      \n","\n","375/375 - 2s - loss: 0.3237 - categorical_accuracy: 0.8850 - val_loss: 0.3386 - val_categorical_accuracy: 0.8818 - 2s/epoch - 4ms/step\n","\n","Epoch 20/50                                                                      \n","\n","375/375 - 2s - loss: 0.3205 - categorical_accuracy: 0.8855 - val_loss: 0.3343 - val_categorical_accuracy: 0.8852 - 2s/epoch - 5ms/step\n","\n","Epoch 21/50                                                                      \n","\n","375/375 - 2s - loss: 0.3161 - categorical_accuracy: 0.8866 - val_loss: 0.3207 - val_categorical_accuracy: 0.8863 - 2s/epoch - 4ms/step\n","\n","Epoch 22/50                                                                      \n","\n","375/375 - 2s - loss: 0.3125 - categorical_accuracy: 0.8870 - val_loss: 0.3415 - val_categorical_accuracy: 0.8812 - 2s/epoch - 4ms/step\n","\n","Epoch 23/50                                                                      \n","\n","375/375 - 2s - loss: 0.3123 - categorical_accuracy: 0.8885 - val_loss: 0.3278 - val_categorical_accuracy: 0.8888 - 2s/epoch - 5ms/step\n","\n","Epoch 24/50                                                                      \n","\n","375/375 - 2s - loss: 0.3062 - categorical_accuracy: 0.8919 - val_loss: 0.3390 - val_categorical_accuracy: 0.8824 - 2s/epoch - 4ms/step\n","\n","Epoch 25/50                                                                      \n","\n","375/375 - 2s - loss: 0.3103 - categorical_accuracy: 0.8891 - val_loss: 0.3397 - val_categorical_accuracy: 0.8861 - 2s/epoch - 4ms/step\n","\n","Epoch 26/50                                                                      \n","\n","375/375 - 2s - loss: 0.3054 - categorical_accuracy: 0.8919 - val_loss: 0.3294 - val_categorical_accuracy: 0.8875 - 2s/epoch - 4ms/step\n","\n","Epoch 27/50                                                                      \n","\n","375/375 - 2s - loss: 0.3085 - categorical_accuracy: 0.8900 - val_loss: 0.3371 - val_categorical_accuracy: 0.8870 - 2s/epoch - 4ms/step\n","\n","Epoch 28/50                                                                      \n","\n","375/375 - 2s - loss: 0.3023 - categorical_accuracy: 0.8926 - val_loss: 0.3483 - val_categorical_accuracy: 0.8832 - 2s/epoch - 5ms/step\n","\n","Epoch 29/50                                                                      \n","\n","375/375 - 2s - loss: 0.3003 - categorical_accuracy: 0.8938 - val_loss: 0.3333 - val_categorical_accuracy: 0.8896 - 2s/epoch - 4ms/step\n","\n","Epoch 30/50                                                                      \n","\n","375/375 - 2s - loss: 0.3038 - categorical_accuracy: 0.8905 - val_loss: 0.3281 - val_categorical_accuracy: 0.8870 - 2s/epoch - 5ms/step\n","\n","Epoch 31/50                                                                      \n","\n","375/375 - 2s - loss: 0.2980 - categorical_accuracy: 0.8935 - val_loss: 0.3433 - val_categorical_accuracy: 0.8868 - 2s/epoch - 5ms/step\n","\n","Epoch 32/50                                                                      \n","\n","375/375 - 2s - loss: 0.2960 - categorical_accuracy: 0.8947 - val_loss: 0.3320 - val_categorical_accuracy: 0.8868 - 2s/epoch - 5ms/step\n","\n","Epoch 33/50                                                                      \n","\n","375/375 - 2s - loss: 0.2954 - categorical_accuracy: 0.8948 - val_loss: 0.3303 - val_categorical_accuracy: 0.8879 - 2s/epoch - 5ms/step\n","\n","Epoch 34/50                                                                      \n","\n","375/375 - 2s - loss: 0.2920 - categorical_accuracy: 0.8951 - val_loss: 0.3383 - val_categorical_accuracy: 0.8891 - 2s/epoch - 4ms/step\n","\n","Epoch 35/50                                                                      \n","\n","375/375 - 2s - loss: 0.2934 - categorical_accuracy: 0.8971 - val_loss: 0.3321 - val_categorical_accuracy: 0.8909 - 2s/epoch - 5ms/step\n","\n","Epoch 36/50                                                                      \n","\n","375/375 - 2s - loss: 0.2916 - categorical_accuracy: 0.8950 - val_loss: 0.3403 - val_categorical_accuracy: 0.8842 - 2s/epoch - 5ms/step\n","\n","Epoch 37/50                                                                      \n","\n","375/375 - 2s - loss: 0.2866 - categorical_accuracy: 0.8996 - val_loss: 0.3428 - val_categorical_accuracy: 0.8893 - 2s/epoch - 4ms/step\n","\n","Epoch 38/50                                                                      \n","\n","375/375 - 2s - loss: 0.2880 - categorical_accuracy: 0.8983 - val_loss: 0.3405 - val_categorical_accuracy: 0.8887 - 2s/epoch - 4ms/step\n","\n","Epoch 39/50                                                                      \n","\n","375/375 - 2s - loss: 0.2864 - categorical_accuracy: 0.8987 - val_loss: 0.3291 - val_categorical_accuracy: 0.8896 - 2s/epoch - 4ms/step\n","\n","Epoch 40/50                                                                      \n","\n","375/375 - 2s - loss: 0.2856 - categorical_accuracy: 0.8990 - val_loss: 0.3347 - val_categorical_accuracy: 0.8915 - 2s/epoch - 5ms/step\n","\n","Epoch 41/50                                                                      \n","\n","375/375 - 2s - loss: 0.2853 - categorical_accuracy: 0.8996 - val_loss: 0.3293 - val_categorical_accuracy: 0.8910 - 2s/epoch - 5ms/step\n","\n","Epoch 42/50                                                                      \n","\n","375/375 - 2s - loss: 0.2821 - categorical_accuracy: 0.8997 - val_loss: 0.3422 - val_categorical_accuracy: 0.8882 - 2s/epoch - 5ms/step\n","\n","Epoch 43/50                                                                      \n","\n","375/375 - 2s - loss: 0.2845 - categorical_accuracy: 0.9003 - val_loss: 0.3357 - val_categorical_accuracy: 0.8907 - 2s/epoch - 4ms/step\n","\n","Epoch 44/50                                                                      \n","\n","375/375 - 2s - loss: 0.2791 - categorical_accuracy: 0.9012 - val_loss: 0.3435 - val_categorical_accuracy: 0.8915 - 2s/epoch - 5ms/step\n","\n","Epoch 45/50                                                                      \n","\n","375/375 - 2s - loss: 0.2826 - categorical_accuracy: 0.9003 - val_loss: 0.3458 - val_categorical_accuracy: 0.8854 - 2s/epoch - 5ms/step\n","\n","Epoch 46/50                                                                      \n","\n","375/375 - 2s - loss: 0.2800 - categorical_accuracy: 0.9001 - val_loss: 0.3535 - val_categorical_accuracy: 0.8875 - 2s/epoch - 5ms/step\n","\n","Epoch 47/50                                                                      \n","\n","375/375 - 2s - loss: 0.2781 - categorical_accuracy: 0.9021 - val_loss: 0.3398 - val_categorical_accuracy: 0.8870 - 2s/epoch - 5ms/step\n","\n","Epoch 48/50                                                                      \n","\n","375/375 - 2s - loss: 0.2791 - categorical_accuracy: 0.9014 - val_loss: 0.3427 - val_categorical_accuracy: 0.8888 - 2s/epoch - 5ms/step\n","\n","Epoch 49/50                                                                      \n","\n","375/375 - 2s - loss: 0.2744 - categorical_accuracy: 0.9029 - val_loss: 0.3487 - val_categorical_accuracy: 0.8913 - 2s/epoch - 5ms/step\n","\n","Epoch 50/50                                                                      \n","\n","375/375 - 2s - loss: 0.2750 - categorical_accuracy: 0.9033 - val_loss: 0.3516 - val_categorical_accuracy: 0.8910 - 2s/epoch - 5ms/step\n","\n","Best validation acc of epoch:                                                    \n","0.8914999961853027                                                               \n","100%|██████████| 5/5 [12:12<00:00, 146.41s/trial, best loss: -0.8914999961853027]\n","Evalutation of best performing model:\n","313/313 [==============================] - 1s 3ms/step - loss: 0.3902 - categorical_accuracy: 0.8828\n","[0.39020416140556335, 0.8827999830245972]\n","Best performing model chosen hyper-parameters:\n","{'Dense': 1, 'Dense_1': 1, 'Dense_2': 0, 'Dropout': 0.34611859763450203, 'Dropout_1': 0.28735631985323384, 'Dropout_2': 0.09664464567700914, 'batch_size': 2, 'optimizer': 0}\n","Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_4 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_16 (Dense)            (None, 128)               100480    \n","                                                                 \n"," dropout_12 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_17 (Dense)            (None, 128)               16512     \n","                                                                 \n"," dropout_13 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_18 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_14 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_19 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 125,898\n","Trainable params: 125,898\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from hyperopt import Trials, tpe\n","\n","best_run, best_model = optim.minimize(model=create_model,\n","                                        data=data,\n","                                        algo=tpe.suggest,\n","                                        max_evals=5,\n","                                        trials=Trials(),\n","                                        notebook_name='10_hyperparameter_tuning')\n","\n","print(\"Evalutation of best performing model:\")\n","print(best_model.evaluate(x_test, y_test))\n","print(\"Best performing model chosen hyper-parameters:\")\n","print(best_run)\n","best_model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now that the hyperparameters have been optimized, we can train a new model from scratch for a greater number of epochs. Additionally, since we \"_know what works_,\" we can try our own experiments in a more constrained research space."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Version:  2.10.1\n","Eager mode:  True\n","GPU is available\n","Epoch 1/16\n","375/375 - 2s - loss: 0.6147 - categorical_accuracy: 0.7744 - val_loss: 0.4280 - val_categorical_accuracy: 0.8407 - 2s/epoch - 6ms/step\n","Epoch 2/16\n","375/375 - 1s - loss: 0.4147 - categorical_accuracy: 0.8459 - val_loss: 0.4122 - val_categorical_accuracy: 0.8516 - 1s/epoch - 4ms/step\n","Epoch 3/16\n","375/375 - 2s - loss: 0.3709 - categorical_accuracy: 0.8647 - val_loss: 0.3909 - val_categorical_accuracy: 0.8550 - 2s/epoch - 4ms/step\n","Epoch 4/16\n","375/375 - 2s - loss: 0.3437 - categorical_accuracy: 0.8733 - val_loss: 0.3474 - val_categorical_accuracy: 0.8750 - 2s/epoch - 5ms/step\n","Epoch 5/16\n","375/375 - 2s - loss: 0.3267 - categorical_accuracy: 0.8794 - val_loss: 0.3353 - val_categorical_accuracy: 0.8772 - 2s/epoch - 4ms/step\n","Epoch 6/16\n","375/375 - 2s - loss: 0.3100 - categorical_accuracy: 0.8854 - val_loss: 0.4000 - val_categorical_accuracy: 0.8599 - 2s/epoch - 4ms/step\n","Epoch 7/16\n","375/375 - 2s - loss: 0.2972 - categorical_accuracy: 0.8892 - val_loss: 0.3640 - val_categorical_accuracy: 0.8743 - 2s/epoch - 4ms/step\n","Epoch 8/16\n","375/375 - 2s - loss: 0.2871 - categorical_accuracy: 0.8933 - val_loss: 0.3450 - val_categorical_accuracy: 0.8777 - 2s/epoch - 4ms/step\n","Epoch 9/16\n","375/375 - 2s - loss: 0.2822 - categorical_accuracy: 0.8947 - val_loss: 0.3375 - val_categorical_accuracy: 0.8838 - 2s/epoch - 5ms/step\n","Epoch 10/16\n","375/375 - 2s - loss: 0.2708 - categorical_accuracy: 0.8994 - val_loss: 0.3583 - val_categorical_accuracy: 0.8760 - 2s/epoch - 5ms/step\n","Epoch 11/16\n","375/375 - 2s - loss: 0.2656 - categorical_accuracy: 0.9013 - val_loss: 0.3892 - val_categorical_accuracy: 0.8665 - 2s/epoch - 6ms/step\n","Epoch 12/16\n","375/375 - 2s - loss: 0.2607 - categorical_accuracy: 0.9033 - val_loss: 0.3660 - val_categorical_accuracy: 0.8857 - 2s/epoch - 5ms/step\n","Epoch 13/16\n","375/375 - 2s - loss: 0.2560 - categorical_accuracy: 0.9044 - val_loss: 0.3729 - val_categorical_accuracy: 0.8823 - 2s/epoch - 5ms/step\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"hoverlabel":{"namelength":-1},"hovertemplate":"Accuracy (Training): %{y:.5f} acc <extra></extra>","line":{"color":"rgba(0, 102, 255, 0.5)","dash":"dash","width":3},"mode":"lines","name":"Accuracy (Training)","showlegend":true,"type":"scatter","x":[1,2,3,4,5,6,7,8,9,10,11,12,13],"y":[0.7743958234786987,0.8458750247955322,0.8646666407585144,0.8732708096504211,0.8794166445732117,0.8853541612625122,0.8892499804496765,0.8932708501815796,0.8946874737739563,0.8993750214576721,0.9012708067893982,0.903333306312561,0.9044374823570251]},{"hoverlabel":{"namelength":-1},"hovertemplate":"Accuracy (Validation): %{y:.2f} acc <extra></extra>","line":{"color":"rgba(255, 0, 0, 0.5)","dash":"dash","width":3},"mode":"lines","name":"Accuracy (Validation)","showlegend":true,"type":"scatter","x":[1,2,3,4,5,6,7,8,9,10,11,12,13],"y":[0.840666651725769,0.8515833616256714,0.8550000190734863,0.875,0.8771666884422302,0.8599166870117188,0.8743333220481873,0.8777499794960022,0.8837500214576721,0.8759999871253967,0.8665000200271606,0.8857499957084656,0.8822500109672546]}],"layout":{"paper_bgcolor":"rgba(0, 0, 0, 0)","plot_bgcolor":"rgba(0, 0, 0, 0)","template":{"data":{"bar":[{"error_x":{"color":"#f2f5fa"},"error_y":{"color":"#f2f5fa"},"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"baxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"line":{"color":"#283442"}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"line":{"color":"#283442"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#506784"},"line":{"color":"rgb(17,17,17)"}},"header":{"fill":{"color":"#2a3f5f"},"line":{"color":"rgb(17,17,17)"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#f2f5fa","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#f2f5fa"},"geo":{"bgcolor":"rgb(17,17,17)","lakecolor":"rgb(17,17,17)","landcolor":"rgb(17,17,17)","showlakes":true,"showland":true,"subunitcolor":"#506784"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"dark"},"paper_bgcolor":"rgb(17,17,17)","plot_bgcolor":"rgb(17,17,17)","polar":{"angularaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","radialaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"yaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"zaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"}},"shapedefaults":{"line":{"color":"#f2f5fa"}},"sliderdefaults":{"bgcolor":"#C8D4E3","bordercolor":"rgb(17,17,17)","borderwidth":1,"tickwidth":0},"ternary":{"aaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"baxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","caxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"title":{"x":0.05},"updatemenudefaults":{"bgcolor":"#506784","borderwidth":0},"xaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2}}}}}},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"hoverlabel":{"namelength":-1},"hovertemplate":"Accuracy (Training): %{y:.5f} acc <extra></extra>","line":{"color":"rgba(0, 102, 255, 0.5)","dash":"dash","width":3},"mode":"lines","name":"Accuracy (Training)","showlegend":true,"type":"scatter","x":[1,2,3,4,5,6,7,8,9,10,11,12,13],"y":[0.7743958234786987,0.8458750247955322,0.8646666407585144,0.8732708096504211,0.8794166445732117,0.8853541612625122,0.8892499804496765,0.8932708501815796,0.8946874737739563,0.8993750214576721,0.9012708067893982,0.903333306312561,0.9044374823570251]},{"hoverlabel":{"namelength":-1},"hovertemplate":"Accuracy (Validation): %{y:.2f} acc <extra></extra>","line":{"color":"rgba(255, 0, 0, 0.5)","dash":"dash","width":3},"mode":"lines","name":"Accuracy (Validation)","showlegend":true,"type":"scatter","x":[1,2,3,4,5,6,7,8,9,10,11,12,13],"y":[0.840666651725769,0.8515833616256714,0.8550000190734863,0.875,0.8771666884422302,0.8599166870117188,0.8743333220481873,0.8777499794960022,0.8837500214576721,0.8759999871253967,0.8665000200271606,0.8857499957084656,0.8822500109672546]}],"layout":{"paper_bgcolor":"rgba(0, 0, 0, 0)","plot_bgcolor":"rgba(0, 0, 0, 0)","template":{"data":{"bar":[{"error_x":{"color":"#f2f5fa"},"error_y":{"color":"#f2f5fa"},"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"baxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"line":{"color":"#283442"}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"line":{"color":"#283442"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#506784"},"line":{"color":"rgb(17,17,17)"}},"header":{"fill":{"color":"#2a3f5f"},"line":{"color":"rgb(17,17,17)"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#f2f5fa","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#f2f5fa"},"geo":{"bgcolor":"rgb(17,17,17)","lakecolor":"rgb(17,17,17)","landcolor":"rgb(17,17,17)","showlakes":true,"showland":true,"subunitcolor":"#506784"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"dark"},"paper_bgcolor":"rgb(17,17,17)","plot_bgcolor":"rgb(17,17,17)","polar":{"angularaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","radialaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"yaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"zaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"}},"shapedefaults":{"line":{"color":"#f2f5fa"}},"sliderdefaults":{"bgcolor":"#C8D4E3","bordercolor":"rgb(17,17,17)","borderwidth":1,"tickwidth":0},"ternary":{"aaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"baxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","caxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"title":{"x":0.05},"updatemenudefaults":{"bgcolor":"#506784","borderwidth":0},"xaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2}}}}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 1s 4ms/step - loss: 0.4008 - categorical_accuracy: 0.8782\n","Final Loss: 0.4.\n","Final Performance: 87.82 %.\n"]}],"source":["import tensorflow as tf\n","\n","model = tf.keras.models.Sequential()\n","\n","model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n","model.add(tf.keras.layers.Dense(64, activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.01))\n","\n","model.add(tf.keras.layers.Dense(256, activation='relu'))\n","model.add(tf.keras.layers.Dropout(0))\n","\n","model.add(tf.keras.layers.Dense(256, activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","model.add(tf.keras.layers.Dense(10, activation='softmax'))\n","\n","model.compile(optimizer='rmsprop',\n","            loss='categorical_crossentropy',\n","            metrics=['categorical_accuracy'])\n","\n","my_callbacks = [\n","    tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n","                                    patience=8),  \n","    tf.keras.callbacks.ModelCheckpoint(filepath='models/model.{epoch:02d}-{val_loss:.2f}.h5', \n","                                        monitor='val_loss', \n","                                        save_best_only=True,),  \n","]\n","\n","print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n","\n","history = model.fit(x_train, y_train,\n","                batch_size=128, epochs=16,\n","                validation_split=0.2, verbose=2,\n","                callbacks=my_callbacks)\n","\n","history_dict = history.history\n","\n","acc = history_dict['categorical_accuracy']\n","val_acc = history_dict['val_categorical_accuracy']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","import plotly.graph_objects as go\n","\n","fig = go.Figure(layout={'template': 'plotly_dark'})\n","\n","fig.add_trace(go.Scatter(x=list(epochs), y=acc,\n","                         line_color='rgba(0, 102, 255, 0.5)', line=dict(width=3, dash='dash'), name='Accuracy (Training)', mode='lines',\n","                         hoverlabel=dict(namelength=-1),\n","                         hovertemplate='Accuracy (Training): %{y:.5f} acc <extra></extra>',\n","                         showlegend=True))\n","fig.add_trace(go.Scatter(x=list(epochs), y=val_acc,\n","                         line_color='rgba(255, 0, 0, 0.5)', line=dict(width=3, dash='dash'), name='Accuracy (Validation)', mode='lines',\n","                         hoverlabel=dict(namelength=-1),\n","                         hovertemplate='Accuracy (Validation): %{y:.2f} acc <extra></extra>',\n","                         showlegend=True))\n","\n","\n","fig.update_layout(\n","    paper_bgcolor='rgba(0, 0, 0, 0)',\n","    plot_bgcolor='rgba(0, 0, 0, 0)'\n","\n",")\n","\n","fig.show()\n","\n","\n","fig2 = go.Figure(layout={'template': 'plotly_dark'})\n","\n","fig2.add_trace(go.Scatter(x=list(epochs), y=loss,\n","                          line_color='rgba(0, 102, 255, 0.5)', line=dict(width=3, dash='dash'), name='Loss (Training)', mode='lines',\n","                          hoverlabel=dict(namelength=-1),\n","                          hovertemplate='Loss (Training): %{y:.5f} loss <extra></extra>',\n","                          showlegend=True))\n","fig2.add_trace(go.Scatter(x=list(epochs), y=val_loss,\n","                          line_color='rgba(255, 0, 0, 0.5)', line=dict(width=3, dash='dash'), name='Loss (Validation)', mode='lines',\n","                          hoverlabel=dict(namelength=-1),\n","                          hovertemplate='Loss (Validation): %{y:.2f} loss <extra></extra>',\n","                          showlegend=True))\n","\n","fig2.update_layout(\n","    paper_bgcolor='rgba(0, 0, 0, 0)',\n","    plot_bgcolor='rgba(0, 0, 0, 0)'\n","\n",")\n","fig.show()\n","\n","test_loss_score, test_acc_score = model.evaluate(x_test, y_test)\n","\n","print(f'Final Loss: {round(test_loss_score, 2)}.')\n","print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Overall, hyperparameter optimization is a potent method that is essential to developing cutting-edge models for any task. 🙃\n","\n","---\n","\n","Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle)."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"}}},"nbformat":4,"nbformat_minor":2}
