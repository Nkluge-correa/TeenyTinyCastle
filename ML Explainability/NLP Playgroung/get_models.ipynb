{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Language Models from Hugging Face ðŸ¤—\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n",
    "\n",
    "**Whit this notebook, you can specify which models you want to download from the [Hugging Face library](https://github.com/huggingface/transformers). The models will be saved in a `my_models` file, in a `.pt` format (_machine learning model created using PyTorch_), together with a folder containing the model's tokenizer (all your main files will be in your main directory at the end). The notebook also _zips_ the model file to help save some memory in your environment (the `my_app.py` will automatically unzip the file and load the model in memory when you run it).**\n",
    "\n",
    "**You can use the Playground both in English and Portuguese (_the `Translator` function from `googletrans` is making the translation during inference time_).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 762/762 [00:00<00:00, 845kB/s]\n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 353M/353M [01:13<00:00, 4.77MB/s] \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:01<00:00, 869kB/s] \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 537kB/s]  \n",
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.36M/1.36M [00:01<00:00, 1.19MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ziping model...\n",
      "We got your model!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import Accelerator\n",
    "\n",
    "name = 'distilgpt2'  # distilgpt2, gpt2, gpt2-medium, gpt2-large, gpt2-xl\n",
    "\n",
    "os.mkdir('temp')\n",
    "print('Getting model...')\n",
    "model = AutoModelForCausalLM.from_pretrained(name)\n",
    "torch.save(model, f'temp\\{name}.pt')\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "tokenizer.save_pretrained(f'temp\\{name}_tokenizer')\n",
    "\n",
    "shutil.move(f'temp\\{name}.pt', f'.\\{name}.pt')\n",
    "shutil.move(f'temp\\{name}_tokenizer', f'.\\{name}_tokenizer')\n",
    "\n",
    "compression = zipfile.ZIP_DEFLATED\n",
    "print('Ziping model...')\n",
    "zf = zipfile.ZipFile(f'{name}.zip', mode='w')\n",
    "zf.write('distilgpt2.pt', 'distilgpt2.pt', compress_type=compression)\n",
    "zf.close()\n",
    "os.remove('distilgpt2.pt')\n",
    "os.rmdir('temp')\n",
    "print('We got your model!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Return to the [castle](https://github.com/Nkluge-correa/teeny-tiny_castle).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
