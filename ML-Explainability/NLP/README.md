# Machine Learning Explainability (Natural Language Processing)

You can find ML Explainability/Interpretability lessons in this folder, mainly focusing on applications involving [natural language processing](../../ML-Explainability/NLP).

Unravel the complexities of natural language processing models and gain insights into their decision-making processes. From sentiment analysis and applying LIME explanations to LSTMs to exploring integrated gradients, interpreting BERT models, word2vector models, and embedding models, each tutorial provides a deep dive into NLP interpretability.

| Tutorial                                             | GitHub                                                                                                                                                        | Colab                                                                                                                                                                                            |
|------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Creating language models for text-classification     | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/model_maker.ipynb" target="_blank">LINK</a>                       | <a href="https://colab.research.google.com/drive/1cHGKZZkhgEp-sRP4zAJZ8rYeikkzfdJf" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |
| Applying LIME explanations to shallow languge models | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/lime_for_NLP.ipynb" target="_blank">LINK</a>                      | <a href="https://colab.research.google.com/drive/1VQXxSgM9wcTUrkUW5vslyjAjE8zxq2oj" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |
| Applying integrated gradients to Language Models     | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/integrated_gradients_in_keras_nlp.ipynb" target="_blank">LINK</a> | <a href="https://colab.research.google.com/drive/1rTVXeecVJ4gLxkeAzMmrlj9ZG31QrXXq" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |
| Explaining DistilBERT with integrated gradients      | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/gradient_explanations_BERT.ipynb" target="_blank">LINK</a>        | <a href="https://colab.research.google.com/drive/1j4N3wkaPv7VME6ClKzKCFINu5wYYvqq-" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |
| Training and Exploring `Word2Vec` models             | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/word2vec.ipynb" target="_blank">LINK</a>                          | <a href="https://colab.research.google.com/drive/1XWVyVIVbLvBd6pXP8UszSAPnijmIl1uv" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |
| Exploring Language Model's Embeddings                | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/investigating_word_embeddings.ipynb" target="_blank">LINK</a>     | <a href="https://colab.research.google.com/drive/1WllP4-DQCdo7icQEDPW_Z_PdTokT4nVe" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |
| Text mining on text datasets                         | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/text_mining.ipynb" target="_blank">LINK</a>                       | <a href="https://colab.research.google.com/drive/15AeaCY8d8LD1ouFt1CbxNqKgFMBazGch" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |
| Dissecting a GPT model                               | <a href="https://github.com/Nkluge-correa/TeenyTinyCastle/blob/master/ML-Explainability/NLP/dissecting_gpt2.ipynb" target="_blank">LINK</a>                   | <a href="https://colab.research.google.com/drive/1S1z970ofN_LhM-OcdFC6BDIG6j5SoC57" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a> |

---

Return to the [castle](https://github.com/Nkluge-correa/TeenyTinyCastle).
