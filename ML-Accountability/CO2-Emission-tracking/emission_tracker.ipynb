{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8OUPkGlVgc4"
      },
      "source": [
        "# Tracking carbon emissions and power consumption with CodeCarbon\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1oZLM3uAHdqdbyVCq67CxHCzWK_ldqMEX\" target=\"_blank\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\">\n",
        "</a>\n",
        "\n",
        "Return to the [castle](https://github.com/Nkluge-correa/TeenyTinyCastle).\n",
        "\n",
        "Recent advancements in Artificial Intelligence, particularly Machine Learning, enable human-level tasks such as image and facial recognition, autonomous driving, and mastering complex games like chess and Go. Achieving such proficiency involves utilizing extensive datasets to learn patterns and features. Consequently, state-of-the-art Machine Learning models require substantial computing power training on advanced processors for weeks or months, leading to significant energy consumption and potential greenhouse gas emissions based on the energy grid used.\n",
        "\n",
        "Amid this scenario, measuring the energy consumption and respective carbon emissions of, for example, training and inference of ML models, is becoming a common practice.\n",
        "\n",
        "<img src=\"https://earthnworld.com/wp-content/webp-express/webp-images/uploads/2021/10/carbon-footprint-scaled.jpg.webp\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "Source: [Earthnworld](https://earthnworld.com/reduce-carbon-footprint/).\n",
        "\n",
        "To help us in this process, we have libraries like [CodeCarbon](https://codecarbon.io/). CodeCarbon is a lightweight software package that can easily be integrated into a Python codebase. This package enables developers to track emissions, measured as kilograms of $CO_2$-equivalents ($CO_2$eq), to estimate their work's carbon footprint.\n",
        "\n",
        "According to CodeCarbon [documentation](https://mlco2.github.io/codecarbon/methodology.html), the package estimates carbon dioxide emissions as the product of two main factors:\n",
        "\n",
        "- $C$: Carbon Intensity of the electricity consumed for computation (grams of C$O_2$ emitted per kilowatt-hour).\n",
        "- $E$: Energy Consumed by the computational infrastructure (kilowatt-hours - kWh).\n",
        "\n",
        "Hence:\n",
        "\n",
        "$$\\text{Carbon dioxide emissions} = C \\times E$$\n",
        "\n",
        "CodeCarbon, when possible, uses the global carbon intensity of electricity per cloud provider or per country to infer the value of $C$. For example, this is the mix of energy sources in the local [energy grid for Brazil](https://github.com/mlco2/codecarbon/blob/master/codecarbon/data/private_infra/global_energy_mix.json):\n",
        "\n",
        "```json\n",
        "\"BRA\": {\n",
        "        \"biofuel_TWh\": 57.6,\n",
        "        \"carbon_intensity\": 158.592,\n",
        "        \"coal_TWh\": 25.22,\n",
        "        \"country_name\": \"Brazil\",\n",
        "        \"fossil_TWh\": 139.21,\n",
        "        \"gas_TWh\": 91.03,\n",
        "        \"hydroelectricity_TWh\": 362.82,\n",
        "        \"iso_code\": \"BRA\",\n",
        "        \"low_carbon_TWh\": 523.37,\n",
        "        \"nuclear_TWh\": 14.7,\n",
        "        \"oil_TWh\": 22.96,\n",
        "        \"other_renewable_TWh\": 57.6,\n",
        "        \"other_renewable_exc_biofuel_TWh\": 0.0,\n",
        "        \"per_capita_Wh\": 3091.456,\n",
        "        \"renewables_TWh\": 508.67,\n",
        "        \"solar_TWh\": 16.75,\n",
        "        \"total_TWh\": 662.58,\n",
        "        \"wind_TWh\": 71.5,\n",
        "        \"year\": 2021\n",
        "    },\n",
        "```\n",
        "\n",
        "According to estimations made in 2021, Brazil has a carbon intensity of 158.592 kgCO2/kWh (and that is our $C$).\n",
        "\n",
        "> **Note: If CodeCarbon does not have access to the global carbon intensity or electricity of a country but has its electricity mix, it computes the carbon intensity of electricity using [this](https://mlco2.github.io/codecarbon/methodology.html#id5) table.**\n",
        "\n",
        "Meanwhile, CodeCarbon monitors power usage by tracking hardware infrastructure, including GPUs (utilizing the [`pynvml`](https://pypi.org/project/pynvml/) library), RAM (using a 3 Watts for 8 GB ratio), and CPUs. The net energy used is calculated as the product of power and time, measured in kWh ($E = \\text{Power} \\times \\text{Time}$), and that is how we get the $E$.\n",
        "\n",
        "This is the method behind CodeCarbon. Now, let us see it in action.\n",
        "\n",
        "Codecarbon supports both online (with internet access) and offline (without internet access) modes. Let us first see the online mode.\n",
        "\n",
        "> **Note: In this tutorial, we only cover the explicit tracking objects (`EmissionsTracker` and `OfflineEmissionsTracker `). However, CodeCarbon also supports tracking with decorators and context managers. Check the [documentation](https://mlco2.github.io/codecarbon/usage.html) for a full explanation of available methods.**\n",
        "\n",
        "To track a process in online mode, we use the `EmissionsTracker` object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LocI_dL4G4Wl",
        "outputId": "1f715f41-81a0-4195-ad5c-2947c1ffbc50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Geo Location: ISO: USA | Country: United States | Region : iowa\n",
            "Emissions: 0.00031273682802557214 | Total Energy Consumption: 0.0006909466935680294\n"
          ]
        }
      ],
      "source": [
        "# First, we install `codecarbon`\n",
        "!pip install codecarbon -q\n",
        "\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "tracker = EmissionsTracker(\n",
        "    project_name=\"your_cool_project_name\", # the name of your project\n",
        "    log_level=\"critical\", # critical will make the EmissionsTracker less verbose\n",
        "    measure_power_secs=15, # query energy consumption stats at every x seconds\n",
        "    output_dir=\"./\", # where to output the report\n",
        "    output_file=\"emissions.csv\", # the name of your report file\n",
        "    tracking_mode='machine', # you can choose to track the energy consumption of the whole machine or an isolated process (`process`)\n",
        ")\n",
        "\n",
        "# Let us see the emissions related to counting to a billion in python\n",
        "\n",
        "tracker.start()\n",
        "\n",
        "for _ in range(1, 1000000001):\n",
        "    pass\n",
        "\n",
        "tracker.stop()\n",
        "\n",
        "# You can get stats directly from the `EmissionsTracker`\n",
        "# For a full list of what you can query, use `dir(tracker)`\n",
        "print(f'Geo Location: ISO: {tracker._geo.country_iso_code} | Country: {tracker._geo.country_name} | Region : {tracker._geo.region}')\n",
        "print(f\"Emissions: {tracker.final_emissions} | Total Energy Consumption: {tracker._total_energy.kWh}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfUsi15_LkNU"
      },
      "source": [
        "The results above may vary from where you are (i.e., the energy mixed inferred by your location and the hardware you use). To see the full report produced by the `EmissionsTracker,` you can also check the output file (`\"emissions.csv\"`), which should be on the specified `output_dir`.\n",
        "\n",
        "You can also configure CodeCarbon by creating a config file (`.codecarbon.config`) on your working directory. For example, let us create a config file and repeat our experiment; however, let us set the `log_level` to debug so our tracker can output information mid-tracking to the terminal.\n",
        "\n",
        "> **Note: Configuration files must be named `.codecarbon.config` and start with a section header `[codecarbon]` as the first line in the file.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS1_IUy6Neyg",
        "outputId": "908cf97b-8ebc-4f67-d00e-3ad5ef3ecb5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 19:55:41] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 19:55:41] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 19:55:41] No GPU found.\n",
            "[codecarbon INFO @ 19:55:41] [setup] CPU Tracking...\n",
            "[codecarbon DEBUG @ 19:55:41] Not using PowerGadget, an exception occurred while instantiating IntelPowerGadget : Platform not supported by Intel Power Gadget\n",
            "[codecarbon DEBUG @ 19:55:41] Not using the RAPL interface, an exception occurred while instantiating IntelRAPL : Intel RAPL files not found at /sys/class/powercap/intel-rapl on linux\n",
            "[codecarbon WARNING @ 19:55:41] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon WARNING @ 19:55:42] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 19:55:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 19:55:42] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 19:55:42]   Platform system: Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 19:55:42]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 19:55:42]   CodeCarbon version: 2.3.2\n",
            "[codecarbon INFO @ 19:55:42]   Available RAM : 12.675 GB\n",
            "[codecarbon INFO @ 19:55:42]   CPU count: 2\n",
            "[codecarbon INFO @ 19:55:42]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 19:55:42]   GPU count: None\n",
            "[codecarbon INFO @ 19:55:42]   GPU model: None\n",
            "[codecarbon DEBUG @ 19:55:42] Not running on AWS\n",
            "[codecarbon DEBUG @ 19:55:42] Not running on Azure\n",
            "[codecarbon DEBUG @ 19:55:42] Not running on GCP\n",
            "[codecarbon INFO @ 19:55:58] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.753046035766602 W\n",
            "[codecarbon DEBUG @ 19:55:58] RAM : 4.75 W during 15.01 s [measurement time: 0.0396]\n",
            "[codecarbon INFO @ 19:55:58] Energy consumed for all CPUs : 0.000178 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon DEBUG @ 19:55:58] CPU : 42.50 W during 15.06 s [measurement time: 0.0131]\n",
            "[codecarbon INFO @ 19:55:58] 0.000198 kWh of electricity used since the beginning.\n",
            "[codecarbon DEBUG @ 19:55:58] last_duration=15.010702848434448\n",
            "------------------------\n",
            "[codecarbon INFO @ 19:56:13] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.753046035766602 W\n",
            "[codecarbon DEBUG @ 19:56:13] RAM : 4.75 W during 14.97 s [measurement time: 0.0130]\n",
            "[codecarbon INFO @ 19:56:13] Energy consumed for all CPUs : 0.000355 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon DEBUG @ 19:56:13] CPU : 42.50 W during 15.00 s [measurement time: 0.0115]\n",
            "[codecarbon INFO @ 19:56:13] 0.000394 kWh of electricity used since the beginning.\n",
            "[codecarbon DEBUG @ 19:56:13] last_duration=14.97286581993103\n",
            "------------------------\n",
            "[codecarbon INFO @ 19:56:28] Energy consumed for RAM : 0.000059 kWh. RAM Power : 4.753046035766602 W\n",
            "[codecarbon DEBUG @ 19:56:28] RAM : 4.75 W during 14.94 s [measurement time: 0.0172]\n",
            "[codecarbon INFO @ 19:56:28] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon DEBUG @ 19:56:28] CPU : 42.50 W during 14.99 s [measurement time: 0.0088]\n",
            "[codecarbon INFO @ 19:56:28] 0.000591 kWh of electricity used since the beginning.\n",
            "[codecarbon DEBUG @ 19:56:28] last_duration=14.938656568527222\n",
            "------------------------\n",
            "[codecarbon INFO @ 19:56:34] Energy consumed for RAM : 0.000067 kWh. RAM Power : 4.753046035766602 W\n",
            "[codecarbon DEBUG @ 19:56:34] RAM : 4.75 W during 5.85 s [measurement time: 0.0017]\n",
            "[codecarbon INFO @ 19:56:34] Energy consumed for all CPUs : 0.000601 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon DEBUG @ 19:56:34] CPU : 42.50 W during 5.85 s [measurement time: 0.0023]\n",
            "[codecarbon INFO @ 19:56:34] 0.000668 kWh of electricity used since the beginning.\n",
            "[codecarbon DEBUG @ 19:56:34] last_duration=5.849087715148926\n",
            "------------------------\n",
            "[codecarbon DEBUG @ 19:56:34] EmissionsData(timestamp='2024-01-12T19:56:34', project_name='your_cool_project_name', run_id='521c3da1-e1cc-4c69-829c-84e64dec3f0d', duration=51.00440335273743, emissions=0.00030232393296936275, emissions_rate=5.927408480372644e-06, cpu_power=42.5, gpu_power=0.0, ram_power=4.753046035766602, cpu_energy=0.0006009079860316382, gpu_energy=0, ram_energy=6.703292515066437e-05, energy_consumed=0.0006679409111823027, country_name='United States', country_iso_code='USA', region='iowa', cloud_provider='', cloud_region='', os='Linux-6.1.58+-x86_64-with-glibc2.35', python_version='3.10.12', codecarbon_version='2.3.2', cpu_count=2, cpu_model='Intel(R) Xeon(R) CPU @ 2.20GHz', gpu_count=None, gpu_model=None, longitude=-95.8517, latitude=41.2591, ram_total_size=12.674789428710938, tracking_mode='machine', on_cloud='N', pue=1.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Geo Location: ISO: USA | Country: United States | Region : iowa\n",
            "Emissions: 0.00030232393296936275 | Total Energy Consumption: 0.0006679409111823027\n"
          ]
        }
      ],
      "source": [
        "# Create a config file\n",
        "with open('.codecarbon.config', 'w+', encoding='utf8') as fp:\n",
        "    fp.write(\"\"\"[codecarbon]\n",
        "    project_name = your_cool_project_name\n",
        "    measure_power_secs = 15\n",
        "    save_to_file = true\n",
        "    output_dir = ./\n",
        "    log_level = DEBUG\n",
        "    tracking_mode = machine\n",
        "    output_file = my_emissions.csv\n",
        "    \"\"\")\n",
        "\n",
        "tracker = EmissionsTracker()\n",
        "\n",
        "tracker.start()\n",
        "\n",
        "for _ in range(1, 1000000001):\n",
        "    pass\n",
        "\n",
        "tracker.stop()\n",
        "\n",
        "print(f'Geo Location: ISO: {tracker._geo.country_iso_code} | Country: {tracker._geo.country_name} | Region : {tracker._geo.region}')\n",
        "print(f\"Emissions: {tracker.final_emissions} | Total Energy Consumption: {tracker._total_energy.kWh}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKQp38_uNd8b"
      },
      "source": [
        "As you can see, the tracker outputs many stats to your terminal every 15 seconds, and you have a new report named `my_emissions.csv`.\n",
        "\n",
        "You can specify other parameters to the tracker object as arguments to the `EmissionsTracker` or variables defined in the `.codecarbon.config` file. For a complete list of what is possible, check the [documentation](https://mlco2.github.io/codecarbon/parameters.html#input-parameters).\n",
        "\n",
        "Now, let us see how to use the offline mode. The offline version of the `OfflineEmissionsTracker ` supports restricted environments without internet access. While the internal computations remain unchanged, a `country_iso_code` parameter, which corresponds to the [3-letter alphabet ISO Code](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes) of the country where the compute infrastructure is hosted, is required to fetch Carbon Intensity details of the regional electricity used. Besides this detail, almost everything else is the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx1JmQp8R1Al",
        "outputId": "a8484000-76d1-4696-8c73-f345015744a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Energy Consumption at step 100000000: 0\n",
            "Total Energy Consumption at step 200000000: 0.00019722925940767862\n",
            "Total Energy Consumption at step 300000000: 0.00039411938381308706\n",
            "Total Energy Consumption at step 400000000: 0.0005910087842068689\n",
            "Total Energy Consumption at step 500000000: 0.0007880947833134638\n",
            "Total Energy Consumption at step 600000000: 0.0009849097121915245\n",
            "Total Energy Consumption at step 700000000: 0.0011820762289086986\n",
            "Total Energy Consumption at step 800000000: 0.0013789584531849017\n",
            "Total Energy Consumption at step 900000000: 0.0015759158381346337\n",
            "Total Energy Consumption at step 1000000000: 0.0017727407270066746\n",
            "Geo Location: ISO: BRA | Country: Brazil | Region : None\n",
            "Emissions: 0.0002846856903989168 | Total Energy Consumption: 0.0017950822891376413\n"
          ]
        }
      ],
      "source": [
        "from codecarbon import OfflineEmissionsTracker\n",
        "\n",
        "tracker = OfflineEmissionsTracker(\n",
        "    country_iso_code=\"BRA\",\n",
        "    project_name=\"your_cool_offline_project_name\",\n",
        "    log_level=\"critical\",\n",
        "    measure_power_secs=15,\n",
        "    output_dir=\"./\",\n",
        "    output_file=\"offline_emissions.csv\",\n",
        "    tracking_mode='machine',\n",
        ")\n",
        "\n",
        "tracker.start()\n",
        "\n",
        "for i in range(1, 1000000001):\n",
        "\n",
        "  # You can query the tracker inside the loop\n",
        "  if i % 100_000_000 == 0:\n",
        "    print(f\"Total Energy Consumption at step {i}: {tracker._total_energy.kWh}\")\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "tracker.stop()\n",
        "\n",
        "print(f'Geo Location: ISO: {tracker._geo.country_iso_code} | Country: {tracker._geo.country_name} | Region : {tracker._geo.region}')\n",
        "print(f\"Emissions: {tracker.final_emissions} | Total Energy Consumption: {tracker._total_energy.kWh}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTOZJX9LTWmB"
      },
      "source": [
        "You can also save stats mid-tracking. For example, you can flush the tracker's stats to your output file mid-tracking using the command `tracker.flush()`. The tracker will write a line in your output file with all tracked stats. Hence, you can have more detailed reports in your output file. Try re-running the cell above by substituting the print statement with a `tracker.flush()`, then check your output file as it is updated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbWp5rjDU6Z-",
        "outputId": "4501aec4-1bc3-4bcb-e46a-8c59d6034573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Geo Location: ISO: BRA | Country: Brazil | Region : None\n",
            "Emissions: 0.0002989726077979654 | Total Energy Consumption: 0.0018851682795977438\n"
          ]
        }
      ],
      "source": [
        "from codecarbon import OfflineEmissionsTracker\n",
        "\n",
        "tracker = OfflineEmissionsTracker(\n",
        "    country_iso_code=\"BRA\",\n",
        "    project_name=\"your_cool_offline_project_name\",\n",
        "    log_level=\"critical\",\n",
        "    measure_power_secs=15,\n",
        "    output_dir=\"./\",\n",
        "    output_file=\"offline_emissions_with_flush.csv\",\n",
        "    tracking_mode='machine',\n",
        ")\n",
        "\n",
        "tracker.start()\n",
        "\n",
        "for i in range(1, 1000000001):\n",
        "\n",
        "  # Flush the tracker every 100M steps\n",
        "  if i % 100_000_000 == 0:\n",
        "    tracker.flush()\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "tracker.stop()\n",
        "\n",
        "print(f'Geo Location: ISO: {tracker._geo.country_iso_code} | Country: {tracker._geo.country_name} | Region : {tracker._geo.region}')\n",
        "print(f\"Emissions: {tracker.final_emissions} | Total Energy Consumption: {tracker._total_energy.kWh}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49YVDkYCVO_S"
      },
      "source": [
        "Now, let us track the training of an ML model on the GPU. Bellow, we are using what we learned to follow the training of a CNN on the MNIST digit dataset. As before, we pass the desired arguments to our tracker, wrapping the computationally expensive part of our process (the `model. fit()` in this case) with our tracker.\n",
        "\n",
        "> **Note: If you can't access a GPU, try running this tutorial on [Colab](https://colab.research.google.com/drive/1oZLM3uAHdqdbyVCq67CxHCzWK_ldqMEX).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHwwZphaVgc9",
        "outputId": "5918c029-b6dd-48d8-97a0-d505706697bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.0/179.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "TensorFlow version: 2.15.0\n",
            "Eager mode:  True\n",
            "GPU is available\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 20)        520       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 20)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 50)        25050     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 50)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2450)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               1225500   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1256080 (4.79 MB)\n",
            "Trainable params: 1256080 (4.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 6s 8ms/step - loss: 0.2214 - accuracy: 0.9344\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0539 - accuracy: 0.9836\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0379 - accuracy: 0.9882\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0265 - accuracy: 0.9920\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0206 - accuracy: 0.9933\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0170 - accuracy: 0.9947\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0130 - accuracy: 0.9961\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0109 - accuracy: 0.9967\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0074 - accuracy: 0.9978\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - accuracy: 0.9969\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9919\n",
            "Final Loss: 0.03.\n",
            "Final Performance: 99.19 %.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "tracker = EmissionsTracker(\n",
        "    project_name=\"conv2d-emissions\",\n",
        "    log_level=\"critical\",\n",
        "    output_dir=\"./\",\n",
        "    output_file=\"emissions_CNN_MNIST.csv\",\n",
        ")\n",
        "\n",
        "# Load MNIST and split it\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "train_images=x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "test_images=x_test.reshape(x_test.shape[0], 28, 28 ,1)\n",
        "\n",
        "train_labels=tf.keras.utils.to_categorical(y_train)\n",
        "test_labels=tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Create a CNN via the Sequential API\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(20, (5,5), padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "    tf.keras.layers.Conv2D(50, (5,5), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(500, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with Adam\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Train and track!\n",
        "tracker.start()\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    batch_size=256, verbose=1)\n",
        "\n",
        "tracker.stop()\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss_score, test_acc_score = model.evaluate(test_images, test_labels)\n",
        "print(f'Final Loss: {test_loss_score:.2f}.')\n",
        "print(f'Final Performance: {test_acc_score * 100:.2f} %.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RQVEeP8Vgc-"
      },
      "source": [
        "One thing we can do now is to generate a report from our `emissions_CIFAR_CNN_GPU.csv file`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "JMfeb9q4cYBo",
        "outputId": "9fe9c25f-6e14-4452-d147-b58a12894497"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Carbon Emission Report\n",
              "\n",
              "|**Duration (Seconds)**|**Emission (KgCO2)**|**Emission Rate (KtCO2/Year)**|**CPU Power (Watts)**|\n",
              "|--------------------------------|-------------------------------------|------------------------------------|--------------------------------|\n",
              "| 42.597785|0.000391|9e-06|42.5|\n",
              "|**GPU Power (Watts)**|**RAMPower (Watts)**|**Power Consumption (CPU - kWh)**|**Power Consumption (GPU - kWh)**|\n",
              "|30.174313| 4.753046|0.000503|0.000562|\n",
              "|**Power Consumption (RAM - kWh)**|**Total Consumption (kWh)**|**Country**| **ISO**|\n",
              "|5.6e-05|0.001121|United States|USA|\n",
              "|**Region**| **Cloud Provider**| **Provider's Region**|**OS**|\n",
              "|nevada| nan| nan|Linux-6.1.58+-x86_64-with-glibc2.35|\n",
              "|**Python Version**| **No. of Processors**|**Provider's CPU Model**| **No. of GPUs**|\n",
              "|3.10.12|2|Intel(R) Xeon(R) CPU @ 2.00GHz|1|\n",
              "|**GPU Model**|**RAM Memory Size (GB)**| **Tracking Mode**|**Cloud-Processed**|\n",
              "|1 x Tesla T4| 12.674789428710938|machine| N|\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "df = pd.read_csv(\"./emissions_CNN_MNIST.csv\")\n",
        "\n",
        "precision = 6\n",
        "\n",
        "report = f'''# Carbon Emission Report\n",
        "\n",
        "|**Duration (Seconds)**|**Emission (KgCO2)**|**Emission Rate (KtCO2/Year)**|**CPU Power (Watts)**|\n",
        "|--------------------------------|-------------------------------------|------------------------------------|--------------------------------|\n",
        "| {round(df.duration[0], precision)}|{round(df.emissions[0], precision)}|{round(df.emissions_rate[0], precision)}|{round(df.cpu_power[0], precision)}|\n",
        "|**GPU Power (Watts)**|**RAMPower (Watts)**|**Power Consumption (CPU - kWh)**|**Power Consumption (GPU - kWh)**|\n",
        "|{round(df.gpu_power[0], precision)}| {round(df.ram_power[0], precision)}|{round(df.cpu_energy[0], precision)}|{round(df.gpu_energy[0], precision)}|\n",
        "|**Power Consumption (RAM - kWh)**|**Total Consumption (kWh)**|**Country**| **ISO**|\n",
        "|{round(df.ram_energy[0], precision)}|{round(df.energy_consumed[0], precision)}|{df.country_name[0]}|{df.country_iso_code[0]}|\n",
        "|**Region**| **Cloud Provider**| **Provider's Region**|**OS**|\n",
        "|{df.region[0]}| {df.cloud_provider[0]}| {df.cloud_region[0]}|{df.os[0]}|\n",
        "|**Python Version**| **No. of Processors**|**Provider's CPU Model**| **No. of GPUs**|\n",
        "|{df.python_version[0]}|{df.cpu_count[0]}|{df.cpu_model[0]}|{df.gpu_count[0]}|\n",
        "|**GPU Model**|**RAM Memory Size (GB)**| **Tracking Mode**|**Cloud-Processed**|\n",
        "|{df.gpu_model[0]}| {df.ram_total_size[0]}|{df.tracking_mode[0]}| {df.on_cloud[0]}|\n",
        "\n",
        "'''\n",
        "display(Markdown(report))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TR9aW0jVgdA"
      },
      "source": [
        "If you have CodeCarbon installed on your machine (_this wont work on Colab_), you can generate a `Dash` app to analyze the results of your experiments. The dashboard displays illustrations to understand the emissions logged from your experiments across projects. To luch the app, run the following CLI command:\n",
        "\n",
        "```bash\n",
        "carbonboard --filepath=\"experiments/emissions.csv\" --port=3333\n",
        "```\n",
        "\n",
        "- **filepath**: the path to the CSV file containing logged information.\n",
        "\n",
        "- **port**: an optional port number, e.g., 8050.\n",
        "\n",
        "With CodeCarbon, you have a simple and straightforward way to keep track of your energy consumption and carbon footprint. Also, other options for CO2 emission tracking exist, like [Eco2AI](https://github.com/sb-ai-lab/Eco2AI), which has a similar interface and user experience to CodeCarbon.\n",
        "\n",
        "---\n",
        "\n",
        "Return to the [castle](https://github.com/Nkluge-correa/TeenyTinyCastle).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
